{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-dd0d0a929a7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#to plot within notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlosses_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_epsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mload_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcast_to_floatx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\backend\\load_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfdev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\_api\\v2\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\lite\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterpreter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpHint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\lite\\experimental\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconvert_op_hints_to_stubs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_potentially_supported_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\lite\\experimental\\nn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTFLiteLSTMCell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfLiteRNNCell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\lite\\python\\lite.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtoco_convert_protos\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_saved_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfreeze_saved_model\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_freeze_saved_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpreter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterpreter\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpreter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_delegate\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaving\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msaving_utils\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_keras_saving_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     os.path.join('tflite_runtime', 'interpreter')):\n\u001b[0;32m     31\u001b[0m   \u001b[1;31m# This file is part of tensorflow package.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpreter_wrapper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pywrap_tensorflow_interpreter_wrapper\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_interpreter_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_tf_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask import render_template,request\n",
    "from datetime import time\n",
    "import pandas as pd1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from flask_jsonpify import jsonpify\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "#importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "#to plot within notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from flask import jsonify \n",
    "\n",
    "from yahoo_fin import stock_info as si\n",
    "\n",
    "def getpriceinfo(symbol):\n",
    "    lp=si.get_live_price(symbol)\n",
    "\n",
    "    \n",
    " \n",
    "    #print(si.get_day_most_active())\n",
    " \n",
    "    # get biggest gainers\n",
    "    #print(si.get_day_gainers())\n",
    " \n",
    "    # get worst performers\n",
    "    #print(si.get_day_losers())\n",
    "    return lp\n",
    "\n",
    "def getqoutetable(symbol):\n",
    "    \n",
    "\n",
    "    qt=si.get_quote_table(symbol, dict_result = False)\n",
    " \n",
    "    #print(si.get_day_most_active())\n",
    " \n",
    "    # get biggest gainers\n",
    "    #print(si.get_day_gainers())\n",
    " \n",
    "    # get worst performers\n",
    "    #print(si.get_day_losers())\n",
    "    return qt\n",
    "\n",
    "# function to calculate percentage difference considering baseValue as 100%\n",
    "def percentageChange(baseValue, currentValue):\n",
    "    return((float(currentValue)-baseValue) / abs(baseValue)) *100.00\n",
    "\n",
    "# function to get the actual value using baseValue and percentage\n",
    "def reversePercentageChange(baseValue, percentage):\n",
    "    return float(baseValue) + float(baseValue * percentage / 100.00)\n",
    "\n",
    "# function to transform a list of values into the list of percentages. For calculating percentages for each element in the list\n",
    "# the base is always the previous element in the list.\n",
    "def transformToPercentageChange(x):\n",
    "    baseValue = x[0]\n",
    "    x[0] = 0\n",
    "    for i in range(1,len(x)):\n",
    "        pChange = percentageChange(baseValue,x[i])\n",
    "        baseValue = x[i]\n",
    "        x[i] = pChange\n",
    "\n",
    "# function to transform a list of percentages to the list of actual values. For calculating actual values for each element in the list\n",
    "# the base is always the previous calculated element in the list.\n",
    "def reverseTransformToPercentageChange(baseValue, x):\n",
    "    x_transform = []\n",
    "    for i in range(0,len(x)):\n",
    "        value = reversePercentageChange(baseValue,x[i])\n",
    "        baseValue = value\n",
    "        x_transform.append(value)\n",
    "    return x_transform\n",
    "\n",
    "#read the data file\n",
    "def predictpriceofdata(stockname):\n",
    "    df = pd.read_csv('data\\\\'+stockname+'.csv')\n",
    "# store the first element in the series as the base value for future use.\n",
    "    baseValue = df['Close'][0]\n",
    "\n",
    "# create a new dataframe which is then transformed into relative percentages\n",
    "    data = df.sort_index(ascending=True, axis=0)\n",
    "    new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "    for i in range(0,len(data)):\n",
    "        new_data['Date'][i] = data['Date'][i]\n",
    "        new_data['Close'][i] = data['Close'][i]\n",
    "\n",
    "# transform the 'Close' series into relative percentages\n",
    "    transformToPercentageChange(new_data['Close'])\n",
    "\n",
    "# set Dat column as the index\n",
    "    new_data.index = new_data.Date\n",
    "    new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# create train and test sets\n",
    "    dataset = new_data.values\n",
    "    train, valid = train_test_split(dataset, train_size=0.99, test_size=0.01, shuffle=False)\n",
    "\n",
    "# convert dataset into x_train and y_train.\n",
    "# prediction_window_size is the size of days windows which will be considered for predicting a future value.\n",
    "    prediction_window_size = 60\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(prediction_window_size,len(train)):\n",
    "        x_train.append(dataset[i-prediction_window_size:i,0])\n",
    "        y_train.append(dataset[i,0])\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "##################################################################################################\n",
    "# create and fit the LSTM network\n",
    "# Initialising the RNN\n",
    "    model = Sequential()\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = 50))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "    model.add(Dense(units = 1))\n",
    "# Compiling the RNN\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "    model.fit(x_train, y_train, epochs = 1, batch_size = 1000)\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "#predicting future values, using past 60 from the train data\n",
    "# for next 10 yrs total_prediction_days is set to 3650 days\n",
    "    total_prediction_days = 3650\n",
    "    inputs = new_data[-total_prediction_days:].values\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "\n",
    "# create future predict list which is a two dimensional list of values.\n",
    "# the first dimension is the total number of future days\n",
    "# the second dimension is the list of values of prediction_window_size size\n",
    "    X_predict = []\n",
    "    for i in range(prediction_window_size,inputs.shape[0]):\n",
    "        X_predict.append(inputs[i-prediction_window_size:i,0])\n",
    "    X_predict = np.array(X_predict)\n",
    "\n",
    "# predict the future\n",
    "    X_predict = np.reshape(X_predict, (X_predict.shape[0],X_predict.shape[1],1))\n",
    "    future_closing_price = model.predict(X_predict)\n",
    "\n",
    "    train, valid = train_test_split(new_data, train_size=0.99, test_size=0.01, shuffle=False)\n",
    "    date_index = pd.to_datetime(train.index)\n",
    "\n",
    "#converting dates into number of days as dates cannot be passed directly to any regression model\n",
    "    x_days = (date_index - pd.to_datetime('1970-01-01')).days\n",
    "\n",
    "# we are doing prediction for next 5 years hence prediction_for_days is set to 1500 days.\n",
    "    prediction_for_days = 300\n",
    "    future_closing_price = future_closing_price[:prediction_for_days]\n",
    "\n",
    "# create a data index for future dates\n",
    "    x_predict_future_dates = np.asarray(pd.RangeIndex(start=x_days[-1] + 1, stop=x_days[-1] + 1 + (len(future_closing_price))))\n",
    "    future_date_index = pd.to_datetime(x_predict_future_dates, origin='1970-01-01', unit='D')\n",
    "    print(future_date_index)\n",
    "\n",
    "# transform a list of relative percentages to the actual values\n",
    "    train_transform = reverseTransformToPercentageChange(baseValue, train['Close'])\n",
    "\n",
    "# for future dates the base value the the value of last element from the training set.\n",
    "    baseValue = train_transform[-1]\n",
    "    valid_transform = reverseTransformToPercentageChange(baseValue, valid['Close'])\n",
    "    future_closing_price_transform = reverseTransformToPercentageChange(baseValue, future_closing_price)\n",
    "\n",
    "# recession peak date is the date on which the index is at the bottom most position.\n",
    "    recessionPeakDate =  future_date_index[future_closing_price_transform.index(min(future_closing_price_transform))]\n",
    "    minCloseInFuture = min(future_closing_price_transform);\n",
    "    print(\"The stock market will reach to its lowest bottom on\", recessionPeakDate)\n",
    "    print(\"The lowest index the stock market will fall to is \", minCloseInFuture)\n",
    "\n",
    "# plot the graphs\n",
    "    plt.figure(figsize=(16,8))\n",
    "    df_x = pd.to_datetime(new_data.index)\n",
    "    plt.plot(date_index,train_transform, label='Close Price History')\n",
    "    plt.plot(future_date_index,future_closing_price_transform, label='Predicted Close')\n",
    "\n",
    "# set the title of the graph\n",
    "    plt.suptitle('Stock Market Predictions', fontsize=16)\n",
    "\n",
    "# set the title of the graph window\n",
    "    fig = plt.gcf()\n",
    "    fig.canvas.set_window_title('Stock Market Predictions')\n",
    "\n",
    "#display the legends\n",
    "    plt.legend()\n",
    "\n",
    "#display the graph\n",
    "    plt.show()\n",
    "    \n",
    "    dictofdateandprice={}\n",
    "    \n",
    "    for i in range(38,50):\n",
    "        dictofdateandprice[str(future_date_index[i])]=future_closing_price_transform[i]\n",
    "    return jsonify(dictofdateandprice)\n",
    "def fetchcurrentmarketprice(stock):\n",
    "    stock1=stock\n",
    "    #for ticker in ticker_list1:\n",
    "    url = 'https://in.finance.yahoo.com/quote/' + stock1\n",
    "    print(url)\n",
    "    session = requests_html.HTMLSession()\n",
    "    r = session.get(url)\n",
    "    content = BeautifulSoup(r.content, 'html')\n",
    "    try:\n",
    "        price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #print(str(content).split('data-reactid=\"47\"'))\n",
    "        openprice = str(content).split('data-reactid=\"49\"')[3].split('</span>')[0].replace('>','')\n",
    "        rangeobt = str(content).split('data-reactid=\"67\"')[2].split('</span>')[0]\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "    except IndexError as e:\n",
    "        price = 0.00\n",
    "        price = price or \"0\"\n",
    "    try:\n",
    "        price = float(price.replace(',',''))\n",
    "    except ValueError as e:\n",
    "        price = 0.00\n",
    "        time.sleep(1)\n",
    "   \n",
    "    print( price)\n",
    "    print(openprice)\n",
    "    print(rangeobt)\n",
    "        #cursor.execute(_SQL, (unidecode.unidecode(ticker[0]), price, unidecode.unidecode(ticker[1]), unidecode.unidecode(ticker[2]), unidecode.unidecode(ticker[3])))\n",
    "    return price\n",
    "\n",
    "\n",
    "\n",
    "#urltofetch='https://www.usatoday.com/story/money/2020/04/22/amazon-doing-free-deliveries-food-banks-during-coronavirus-emergency/2997254001/'\n",
    "\n",
    "#alldata=parsenews(urltofetch)\n",
    "#print(alldata)\n",
    "\n",
    "#Python program to scrape website  \n",
    "#and save quotes from website \n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import csv \n",
    "import re\n",
    "\n",
    "def callingnews(query):\n",
    "\n",
    "    URL = \"https://www.usatoday.com/search/?q=\"+query\n",
    "    r = requests.get(URL) \n",
    "#print(r)\n",
    "  \n",
    "    soup = BeautifulSoup(r.content, 'html.parser') \n",
    "#print(soup)\n",
    "    quotes=[]  # a list to store quotes \n",
    "  \n",
    "\n",
    "    table1 = soup.find_all('a', attrs = {'class':'gnt_se_a gnt_se_a__hd gnt_se_a__hi'}) \n",
    "    #print(table1)\n",
    "\n",
    "#table13 = table11.get_text()\n",
    "#print(table13) \n",
    "\n",
    "    table11 = soup.find_all('div', attrs = {'class':'gnt_pr'}) \n",
    "    #print(table11)\n",
    "    datalist=[]\n",
    "    linksdata=[]\n",
    "#print(table11)\n",
    "    for ik in table1:\n",
    "        datalist.append(ik.get_text())\n",
    "        print(ik.get_text())\n",
    "\n",
    "    pos=0\n",
    "    listtocheck=[]\n",
    "    for ik in table1:\n",
    "        links = re.findall(\"href=[\\\"\\'](.*?)[\\\"\\']\", str(ik))\n",
    "        linksdata.append('https://www.usatoday.com'+links[0])\n",
    "        if 'story' not in links[0]:\n",
    "            listtocheck.append(pos)\n",
    "        pos+=1\n",
    "        print(links)\n",
    "\n",
    "    print(\"list check is \",listtocheck)\n",
    "\n",
    "    for ij in range(len(listtocheck)):\n",
    "        print(ij)\n",
    "        datalist.pop(ij)\n",
    "        linksdata.pop(ij)\n",
    "    #print(listtocheck[ij])\n",
    "\n",
    "    print(len(datalist))\n",
    "    print(len(linksdata))\n",
    "    return datalist,linksdata\n",
    "\n",
    "\n",
    "#df\n",
    "df1=pd1.read_csv('fortune500.csv')\n",
    "df=pd.DataFrame()\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route(\"/parsenews\")\n",
    "def parsenews(): \n",
    "    newsinfo = request.args.get('msg')\n",
    "    URL =newsinfo.rstrip().lstrip().strip()# \"https://www.hindustantimes.com/delhi-news/protest-at-delhi-s-jama-masjid-against-citizenship-act-4-metro-stations-closed-in-area/story-q7vKj5IUdIKMExw5eGBfxI.html\"\n",
    "    #URL =\"https://www.hindustantimes.com/delhi-news/protest-at-delhi-s-jama-masjid-against-citizenship-act-4-metro-stations-closed-in-area/story-q7vKj5IUdIKMExw5eGBfxI.html\"\n",
    "    #print repr(URL)\n",
    "    r = requests.get(URL) \n",
    "    #print(r)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser') \n",
    "  \n",
    "    quotes=[]  # a list to store quotes \n",
    "  \n",
    "    table = soup.find('div', attrs = {'class':'gnt_ar_b'}) \n",
    "    #print(table)\n",
    "    alltestdata='<a href=\\''+URL+'\\' target=\"_blank\" >'+URL+'</a>'+'<br>'\n",
    "    print(alltestdata)\n",
    "    try:\n",
    "        table1 = table.find_all('p')\n",
    "        \n",
    "        for row in table.find_all('p'):\n",
    "            quote = {} \n",
    "            quote['data'] = row.text \n",
    "            alltestdata=alltestdata+row.text+\" \"\n",
    "            quotes.append(quote)\n",
    "    except:\n",
    "        alltestdata='<a href=\\''+URL+'\\' target=\"_blank\" >'+URL+'</a>'+'<br>'\n",
    "    #print(alltestdata)\n",
    "    print(alltestdata)\n",
    "    return alltestdata\n",
    "\n",
    "@app.route(\"/searchforcompany\")\n",
    "def searchforcompany():\n",
    "    global df\n",
    "    legend = 'Stock Price data'\n",
    "    company = request.args.get('company')\n",
    "    dfop=df1.loc[df1['Name'] == company]\n",
    "    op1=str(dfop['Symbol'].iloc[0])\n",
    "    print(op1)\n",
    "    df=pd1.read_csv('data//'+op1+'.csv')\n",
    "    temperatures = list(df['Close'])\n",
    "    times = list(df['Date'])\n",
    "    \n",
    "    datalist,linksdata=callingnews(company)\n",
    "    dictis={}\n",
    "    for ims in range(len(datalist)):\n",
    "        dictis[datalist[ims]]=linksdata[ims]\n",
    "        \n",
    "    print(dictis)\n",
    "    urlofsite='https://www.usatoday.com'\n",
    "    io=0\n",
    "    return render_template('line_chart.html',dictdata=dictis,links=linksdata,news=datalist, values=temperatures, labels=times, legend=legend,stockname=company,symbolis=op1)\n",
    "    #return op1\n",
    "\n",
    "@app.route(\"/futurepriceprediction\")\n",
    "def futurepriceprediction():\n",
    "    companySymbol = request.args.get('msg')\n",
    "    dictis=predictpriceofdata(companySymbol)\n",
    "    #print('price is')\n",
    "    print(dictis)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return dictis\n",
    "\n",
    "    \n",
    "    \n",
    "@app.route(\"/fetchprice\")\n",
    "def fetchprice():\n",
    "    company = request.args.get('msg')\n",
    "    priceis=getpriceinfo(company)#'1211'#fetchcurrentmarketprice(company)\n",
    "    print('price is')\n",
    "    print(priceis)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return str(priceis)\n",
    "\n",
    "\n",
    "@app.route(\"/getqoutetableval\")\n",
    "def getqoutetableval():\n",
    "    company = request.args.get('msg')\n",
    "    print('company for qoute '+company)\n",
    "    qoute=getqoutetable(company)#'1211'#fetchcurrentmarketprice(company)\n",
    "    print('qoute is')\n",
    "    print(qoute)\n",
    "    df_list = qoute.values.tolist()\n",
    "    alldata=''\n",
    "    for ik in range(len(df_list)):\n",
    "        alldata=alldata+str(df_list[ik][0])+\" :- \"+str(df_list[ik][1])+\"<br>\\n\"\n",
    "    #JSONP_data = jsonpify(df_list)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return alldata\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    temperatures = dict(df1['Name'])\n",
    "    sendingcompaniesinfo={}\n",
    "    for keys in temperatures: \n",
    "        temperatures[keys] = str(temperatures[keys]) \n",
    "        sendingcompaniesinfo[temperatures[keys]]='null'\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return render_template('searching.html', values=sendingcompaniesinfo)\n",
    "\n",
    "@app.route(\"/simple_chart\")\n",
    "def chart():\n",
    "    legend = 'Monthly Data'\n",
    "    labels = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\"]\n",
    "    values = [10, 9, 8, 7, 6, 4, 7, 8]\n",
    "    return render_template('chart.html', values=values, labels=labels, legend=legend)\n",
    "\n",
    "\n",
    "@app.route(\"/line_chart\")\n",
    "def line_chart():\n",
    "    legend = 'Temperatures'\n",
    "    temperatures = list(df['Close'])\n",
    "    times = list(df['Date'])\n",
    "    return render_template('line_chart.html', values=temperatures, labels=times, legend=legend)\n",
    "\n",
    "@app.route(\"/price\")\n",
    "def price():\n",
    "    global df\n",
    "    userText = request.args.get('msg')\n",
    "    print(userText)\n",
    "    op=dict(df.iloc[int(userText)])#tuple(list(df.iloc[int(userText)]))\n",
    "    print(op)\n",
    "    #for dicts in test_list: \n",
    "    for keys in op: \n",
    "        op[keys] = str(op[keys]) \n",
    "    return op\n",
    "\n",
    "@app.route(\"/time_chart\")\n",
    "def time_chart():\n",
    "    legend = 'Temperatures'\n",
    "    temperatures = [73.7, 73.4, 73.8, 72.8, 68.7, 65.2,\n",
    "                    61.8, 58.7, 58.2, 58.3, 60.5, 65.7,\n",
    "                    70.2, 71.4, 71.2, 70.9, 71.3, 71.1]\n",
    "    times = [time(hour=11, minute=14, second=15),\n",
    "             time(hour=11, minute=14, second=30),\n",
    "             time(hour=11, minute=14, second=45),\n",
    "             time(hour=11, minute=15, second=00),\n",
    "             time(hour=11, minute=15, second=15),\n",
    "             time(hour=11, minute=15, second=30),\n",
    "             time(hour=11, minute=15, second=45),\n",
    "             time(hour=11, minute=16, second=00),\n",
    "             time(hour=11, minute=16, second=15),\n",
    "             time(hour=11, minute=16, second=30),\n",
    "             time(hour=11, minute=16, second=45),\n",
    "             time(hour=11, minute=17, second=00),\n",
    "             time(hour=11, minute=17, second=15),\n",
    "             time(hour=11, minute=17, second=30),\n",
    "             time(hour=11, minute=17, second=45),\n",
    "             time(hour=11, minute=18, second=00),\n",
    "             time(hour=11, minute=18, second=15),\n",
    "             time(hour=11, minute=18, second=30)]\n",
    "    return render_template('time_chart.html', values=temperatures, labels=times, legend=legend)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #app.run('0.0.0.0')\n",
    "    app.run('0.0.0.0',port=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_jsonpify import jsonpify\n",
    "qoute=getqoutetable('amzn')#'1211'#fetchcurrentmarketprice(company)\n",
    "#print('qoute is')\n",
    "#print(qoute)\n",
    "df_list = qoute.values.tolist()\n",
    "print(df_list)\n",
    "print(df_list[0][0])\n",
    "print(df_list[0][1])\n",
    "print(df_list[1][0])\n",
    "print(df_list[2][0])\n",
    "\n",
    "alldata=''\n",
    "for ik in range(len(df_list)):\n",
    "    alldata=alldata+str(df_list[ik][0])+str(df_list[ik][1])+\"\\n\"\n",
    "\n",
    "print(alldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask import render_template,request\n",
    "from datetime import time\n",
    "import pandas as pd1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from flask_jsonpify import jsonpify\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "#from datetime import timedelta\n",
    "import time\n",
    "from flask_wtf import Form\n",
    "from wtforms.fields.html5 import DateField\n",
    "#importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#to plot within notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from flask import jsonify \n",
    "\n",
    "from yahoo_fin import stock_info as si\n",
    "\n",
    "def getpriceinfo(symbol):\n",
    "    lp=si.get_live_price(symbol)\n",
    "\n",
    "    \n",
    " \n",
    "    #print(si.get_day_most_active())\n",
    " \n",
    "    # get biggest gainers\n",
    "    #print(si.get_day_gainers())\n",
    " \n",
    "    # get worst performers\n",
    "    #print(si.get_day_losers())\n",
    "    return lp\n",
    "\n",
    "def getqoutetable(symbol):\n",
    "    \n",
    "\n",
    "    qt=si.get_quote_table(symbol, dict_result = False)\n",
    " \n",
    "    #print(si.get_day_most_active())\n",
    " \n",
    "    # get biggest gainers\n",
    "    #print(si.get_day_gainers())\n",
    " \n",
    "    # get worst performers\n",
    "    #print(si.get_day_losers())\n",
    "    return qt\n",
    "\n",
    "# function to calculate percentage difference considering baseValue as 100%\n",
    "def percentageChange(baseValue, currentValue):\n",
    "    return((float(currentValue)-baseValue) / abs(baseValue)) *100.00\n",
    "\n",
    "# function to get the actual value using baseValue and percentage\n",
    "def reversePercentageChange(baseValue, percentage):\n",
    "    return float(baseValue) + float(baseValue * percentage / 100.00)\n",
    "\n",
    "# function to transform a list of values into the list of percentages. For calculating percentages for each element in the list\n",
    "# the base is always the previous element in the list.\n",
    "def transformToPercentageChange(x):\n",
    "    baseValue = x[0]\n",
    "    x[0] = 0\n",
    "    for i in range(1,len(x)):\n",
    "        pChange = percentageChange(baseValue,x[i])\n",
    "        baseValue = x[i]\n",
    "        x[i] = pChange\n",
    "\n",
    "# function to transform a list of percentages to the list of actual values. For calculating actual values for each element in the list\n",
    "# the base is always the previous calculated element in the list.\n",
    "def reverseTransformToPercentageChange(baseValue, x):\n",
    "    x_transform = []\n",
    "    for i in range(0,len(x)):\n",
    "        value = reversePercentageChange(baseValue,x[i])\n",
    "        baseValue = value\n",
    "        x_transform.append(value)\n",
    "    return x_transform\n",
    "\n",
    "#read the data file\n",
    "def predictpriceofdata(stockname):\n",
    "    \n",
    "\n",
    "# convert dataset into x_train and y_train.\n",
    "# prediction_window_size is the size of days windows which will be considered for predicting a future value.\n",
    "    \n",
    "    dictofdateandprice={}\n",
    "    \n",
    "    for i in range(38,50):\n",
    "        dictofdateandprice[str(future_date_index[i])]=1000\n",
    "    return jsonify(dictofdateandprice)\n",
    "def fetchcurrentmarketprice(stock):\n",
    "    stock1=stock\n",
    "    #for ticker in ticker_list1:\n",
    "    url = 'https://in.finance.yahoo.com/quote/' + stock1\n",
    "    print(url)\n",
    "    session = requests_html.HTMLSession()\n",
    "    r = session.get(url)\n",
    "    content = BeautifulSoup(r.content, 'html')\n",
    "    try:\n",
    "        price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #print(str(content).split('data-reactid=\"47\"'))\n",
    "        openprice = str(content).split('data-reactid=\"49\"')[3].split('</span>')[0].replace('>','')\n",
    "        rangeobt = str(content).split('data-reactid=\"67\"')[2].split('</span>')[0]\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "    except IndexError as e:\n",
    "        price = 0.00\n",
    "        price = price or \"0\"\n",
    "    try:\n",
    "        price = float(price.replace(',',''))\n",
    "    except ValueError as e:\n",
    "        price = 0.00\n",
    "        time.sleep(1)\n",
    "   \n",
    "    print( price)\n",
    "    print(openprice)\n",
    "    print(rangeobt)\n",
    "        #cursor.execute(_SQL, (unidecode.unidecode(ticker[0]), price, unidecode.unidecode(ticker[1]), unidecode.unidecode(ticker[2]), unidecode.unidecode(ticker[3])))\n",
    "    return price\n",
    "\n",
    "\n",
    "\n",
    "#urltofetch='https://www.usatoday.com/story/money/2020/04/22/amazon-doing-free-deliveries-food-banks-during-coronavirus-emergency/2997254001/'\n",
    "\n",
    "#alldata=parsenews(urltofetch)\n",
    "#print(alldata)\n",
    "\n",
    "#Python program to scrape website  \n",
    "#and save quotes from website \n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import csv \n",
    "import re\n",
    "from datetime import date, timedelta\n",
    "\n",
    "def callingnews(query):\n",
    "\n",
    "    URL = \"https://www.usatoday.com/search/?q=\"+query\n",
    "    r = requests.get(URL) \n",
    "#print(r)\n",
    "  \n",
    "    soup = BeautifulSoup(r.content, 'html.parser') \n",
    "#print(soup)\n",
    "    quotes=[]  # a list to store quotes \n",
    "  \n",
    "\n",
    "    table1 = soup.find_all('a', attrs = {'class':'gnt_se_a gnt_se_a__hd gnt_se_a__hi'}) \n",
    "    #print(table1)\n",
    "\n",
    "#table13 = table11.get_text()\n",
    "#print(table13) \n",
    "\n",
    "    table11 = soup.find_all('div', attrs = {'class':'gnt_pr'}) \n",
    "    #print(table11)\n",
    "    datalist=[]\n",
    "    linksdata=[]\n",
    "#print(table11)\n",
    "    for ik in table1:\n",
    "        datalist.append(ik.get_text())\n",
    "        print(ik.get_text())\n",
    "\n",
    "    pos=0\n",
    "    listtocheck=[]\n",
    "    for ik in table1:\n",
    "        links = re.findall(\"href=[\\\"\\'](.*?)[\\\"\\']\", str(ik))\n",
    "        linksdata.append('https://www.usatoday.com'+links[0])\n",
    "        if 'story' not in links[0]:\n",
    "            listtocheck.append(pos)\n",
    "        pos+=1\n",
    "        print(links)\n",
    "\n",
    "    print(\"list check is \",listtocheck)\n",
    "\n",
    "    for ij in range(len(listtocheck)):\n",
    "        print(ij)\n",
    "        datalist.pop(ij)\n",
    "        linksdata.pop(ij)\n",
    "    #print(listtocheck[ij])\n",
    "\n",
    "    print(len(datalist))\n",
    "    print(len(linksdata))\n",
    "    return datalist,linksdata\n",
    "\n",
    "\n",
    "#df\n",
    "df1=pd1.read_csv('fortune500.csv')\n",
    "df=pd.DataFrame()\n",
    "app = Flask(__name__)\n",
    "\n",
    "class ExampleForm(Form):\n",
    "    dt = DateField('container', format='%d-%m-%Y')\n",
    "\n",
    "@app.route(\"/parsenews\")\n",
    "def parsenews(): \n",
    "    newsinfo = request.args.get('msg')\n",
    "    URL =newsinfo.rstrip().lstrip().strip()# \"https://www.hindustantimes.com/delhi-news/protest-at-delhi-s-jama-masjid-against-citizenship-act-4-metro-stations-closed-in-area/story-q7vKj5IUdIKMExw5eGBfxI.html\"\n",
    "    #URL =\"https://www.hindustantimes.com/delhi-news/protest-at-delhi-s-jama-masjid-against-citizenship-act-4-metro-stations-closed-in-area/story-q7vKj5IUdIKMExw5eGBfxI.html\"\n",
    "    #print repr(URL)\n",
    "    r = requests.get(URL) \n",
    "    #print(r)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser') \n",
    "  \n",
    "    quotes=[]  # a list to store quotes \n",
    "  \n",
    "    table = soup.find('div', attrs = {'class':'gnt_ar_b'}) \n",
    "    #print(table)\n",
    "    alltestdata='<a href=\\''+URL+'\\' target=\"_blank\" >'+URL+'</a>'+'<br>'\n",
    "    print(alltestdata)\n",
    "    try:\n",
    "        table1 = table.find_all('p')\n",
    "        \n",
    "        for row in table.find_all('p'):\n",
    "            quote = {} \n",
    "            quote['data'] = row.text \n",
    "            alltestdata=alltestdata+row.text+\" \"\n",
    "            quotes.append(quote)\n",
    "    except:\n",
    "        alltestdata='<a href=\\''+URL+'\\' target=\"_blank\" >'+URL+'</a>'+'<br>'\n",
    "    #print(alltestdata)\n",
    "    print(alltestdata)\n",
    "    return alltestdata\n",
    "\n",
    "@app.route(\"/searchforcompany\")\n",
    "def searchforcompany():\n",
    "    global df\n",
    "    legend = 'Stock Price data'\n",
    "    company =request.args.get('company')\n",
    "    dfop=df1.loc[df1['Name'] == company]\n",
    "    op1=str(dfop['Symbol'].iloc[0])\n",
    "    print(op1)\n",
    "    df=pd1.read_csv('data//'+op1+'.csv')\n",
    "    temperatures = list(df['Close'])\n",
    "    times = list(df['Date'])\n",
    "    \n",
    "    datalist,linksdata=callingnews(company)\n",
    "    dictis={}\n",
    "    for ims in range(len(datalist)):\n",
    "        dictis[datalist[ims]]=linksdata[ims]\n",
    "        \n",
    "    print(dictis)\n",
    "    urlofsite='https://www.usatoday.com'\n",
    "    io=0\n",
    "    return render_template('line_chart.html',dictdata=dictis,links=linksdata,news=datalist, values=temperatures, labels=times, legend=legend,stockname=company,symbolis=op1)\n",
    "    #return op1\n",
    "\n",
    "@app.route(\"/futurepriceprediction\")\n",
    "def futurepriceprediction():\n",
    "    companySymbol = request.args.get('msg')\n",
    "    dictis=predictpriceofdata(companySymbol)\n",
    "    #print('price is')\n",
    "    print(dictis)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return dictis   \n",
    "    \n",
    "@app.route(\"/fetchprice\")\n",
    "def fetchprice():\n",
    "    company = request.args.get('msg')\n",
    "    priceis=getpriceinfo(company)#'1211'#fetchcurrentmarketprice(company)\n",
    "    print('price is')\n",
    "    print(priceis)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return str(priceis)\n",
    "\n",
    "\n",
    "@app.route(\"/getqoutetableval\")\n",
    "def getqoutetableval():\n",
    "    company = request.args.get('msg')\n",
    "    print('company for qoute '+company)\n",
    "    qoute=getqoutetable(company)#'1211'#fetchcurrentmarketprice(company)\n",
    "    print('qoute is')\n",
    "    print(qoute)\n",
    "    df_list = qoute.values.tolist()\n",
    "    alldata=''\n",
    "    for ik in range(len(df_list)):\n",
    "        alldata=alldata+str(df_list[ik][0])+\" :- \"+str(df_list[ik][1])+\"<br>\\n\"\n",
    "    #JSONP_data = jsonpify(df_list)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return alldata\n",
    "\n",
    "@app.route(\"/\")\n",
    "def searching():\n",
    "    temperatures = dict(df1['Name'])\n",
    "    sendingcompaniesinfo={}\n",
    "    for keys in temperatures: \n",
    "        temperatures[keys] = str(temperatures[keys]) \n",
    "        sendingcompaniesinfo[temperatures[keys]]='null'\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return render_template('searching.html', values=sendingcompaniesinfo)\n",
    "\n",
    "@app.route(\"/index\")\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route(\"/contact\")\n",
    "def contact():\n",
    "    return render_template('contact.html')\n",
    "\n",
    "@app.route(\"/embedpdf\")\n",
    "def embedpdf():\n",
    "    return render_template('embedpdf.html')\n",
    "\n",
    "@app.route(\"/about\")\n",
    "def about():\n",
    "    return render_template('about.html')\n",
    "\n",
    "@app.route(\"/prediction\", methods=[\"GET\", \"POST\"])\n",
    "def prediction():\n",
    "    return render_template('prediction.html')\n",
    "\n",
    "@app.route(\"/simple_chart\")\n",
    "def chart():\n",
    "    legend = 'Monthly Data'\n",
    "    labels = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\"]\n",
    "    values = [10, 9, 8, 7, 6, 4, 7, 8]\n",
    "    return render_template('chart.html', values=values, labels=labels, legend=legend)\n",
    "\n",
    "\n",
    "@app.route(\"/line_chart\")\n",
    "def line_chart():\n",
    "    legend = 'Temperatures'\n",
    "    temperatures = list(df['Close'])\n",
    "    times = list(df['Date'])\n",
    "    return render_template('line_chart.html', values=temperatures, labels=times, legend=legend)\n",
    "\n",
    "@app.route(\"/price\")\n",
    "def price():\n",
    "    global df\n",
    "    userText = request.args.get('msg')\n",
    "    print(userText)\n",
    "    op=dict(df.iloc[int(userText)])#tuple(list(df.iloc[int(userText)]))\n",
    "    print(op)\n",
    "    #for dicts in test_list: \n",
    "    for keys in op: \n",
    "        op[keys] = str(op[keys]) \n",
    "    return op\n",
    "\n",
    "\n",
    "@app.route(\"/time_chart\", methods=['POST','GET'])\n",
    "def time_chart():\n",
    "    legend = 'Temperatures'\n",
    "    temperatures = [73.7, 73.4, 73.8, 72.8, 68.7, 65.2,\n",
    "                    61.8, 58.7, 58.2, 58.3, 60.5, 65.7,\n",
    "                    70.2, 71.4, 71.2, 70.9, 71.3, 71.1]\n",
    "    times = [time(hour=11, minute=14, second=15),\n",
    "    time(hour=11, minute=14, second=30),\n",
    "    time(hour=11, minute=14, second=45),\n",
    "    time(hour=11, minute=15, second=00),\n",
    "    time(hour=11, minute=15, second=15),\n",
    "    time(hour=11, minute=15, second=30),\n",
    "    time(hour=11, minute=15, second=45),\n",
    "    time(hour=11, minute=16, second=00),\n",
    "    time(hour=11, minute=16, second=15),\n",
    "    time(hour=11, minute=16, second=30),\n",
    "    time(hour=11, minute=16, second=45),\n",
    "    time(hour=11, minute=17, second=00),\n",
    "    time(hour=11, minute=17, second=15),\n",
    "    time(hour=11, minute=17, second=30),\n",
    "    time(hour=11, minute=17, second=45),\n",
    "    time(hour=11, minute=18, second=00),\n",
    "    time(hour=11, minute=18, second=15),\n",
    "    time(hour=11, minute=18, second=30)]\n",
    "    \n",
    "    #return render_template('time_chart.html', values=temperatures, labels=times, legend=legend)\n",
    "    return render_template('time_chart.html')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run('0.0.0.0')\n",
    "    #app.run('0.0.0.0',port=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'future_date_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-92e826264962>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture_date_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'future_date_index' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-67-f8b3b1e59c1a>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-67-f8b3b1e59c1a>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    X_predict = []\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# create future predict list which is a two dimensional list of values.\n",
    "        # the first dimension is the total number of future days\n",
    "        # the second dimension is the list of values of prediction_window_size size\n",
    "        X_predict = []\n",
    "        for i in range(prediction_window_size,inputs.shape[0]):\n",
    "            X_predict.append(inputs[i-prediction_window_size:i,0])\n",
    "        X_predict = np.array(X_predict)\n",
    "\n",
    "# predict the future\n",
    "        X_predict = np.reshape(X_predict, (X_predict.shape[0],X_predict.shape[1],1))\n",
    "        future_closing_price = model.predict(X_predict)\n",
    "\n",
    "        train, valid = train_test_split(new_data, train_size=0.99, test_size=0.01, shuffle=False)\n",
    "        date_index = pd.to_datetime(train.index)\n",
    "\n",
    "#converting dates into number of days as dates cannot be passed directly to any regression model\n",
    "        x_days = (date_index - pd.to_datetime('1970-01-01')).days\n",
    "\n",
    "# we are doing prediction for next 5 years hence prediction_for_days is set to 1500 days.\n",
    "        prediction_for_days = 60\n",
    "        future_closing_price = future_closing_price[:prediction_for_days]\n",
    "\n",
    "# create a data index for future dates\n",
    "        x_predict_future_dates = np.asarray(pd.RangeIndex(start=x_days[-1] + 1, stop=x_days[-1] + 1 + (len(future_closing_price))))\n",
    "        future_date_index = pd.to_datetime(x_predict_future_dates, origin='1970-01-01', unit='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as ml\n",
    "print(ml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
