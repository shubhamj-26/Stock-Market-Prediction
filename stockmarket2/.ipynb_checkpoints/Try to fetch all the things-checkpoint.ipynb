{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas_datareader\n",
    "# !pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TSLA_2020–04–25\n"
     ]
    }
   ],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "from datetime import date\n",
    "import yfinance as yf\n",
    "yf.pdr_override()\n",
    "import pandas as pd\n",
    "# Tickers list\n",
    "# We can add and delete any ticker from the list to get desired ticker live data\n",
    "ticker_list=['TSLA']\n",
    "today = date.today()\n",
    "# We can get data by our choice by giving days bracket\n",
    "start_date= \"2020–04–21\"\n",
    "end_date=\"2020–04–25\"\n",
    "files=[]\n",
    "def getData(ticker):\n",
    "    print (ticker)\n",
    "    data = pdr.get_data_yahoo(ticker, start='2015-01-01', end='2020-06-12',)\n",
    "    dataname= ticker+'_'+str(end_date)\n",
    "    print(dataname)\n",
    "    files.append(dataname)\n",
    "    SaveData(data, dataname)\n",
    "# Create a data folder in your current dir.\n",
    "def SaveData(df, filename):\n",
    "    df.to_csv(filename+'.csv')\n",
    "#This loop will iterate over ticker list, will pass one ticker to get data, and save that data as file.\n",
    "for tik in ticker_list:\n",
    "    getData(tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>44.618000</td>\n",
       "      <td>45.136002</td>\n",
       "      <td>44.450001</td>\n",
       "      <td>44.481998</td>\n",
       "      <td>44.481998</td>\n",
       "      <td>11487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>44.574001</td>\n",
       "      <td>44.650002</td>\n",
       "      <td>42.652000</td>\n",
       "      <td>43.862000</td>\n",
       "      <td>43.862000</td>\n",
       "      <td>23822000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>42.910000</td>\n",
       "      <td>43.299999</td>\n",
       "      <td>41.431999</td>\n",
       "      <td>42.018002</td>\n",
       "      <td>42.018002</td>\n",
       "      <td>26842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>42.012001</td>\n",
       "      <td>42.840000</td>\n",
       "      <td>40.841999</td>\n",
       "      <td>42.256001</td>\n",
       "      <td>42.256001</td>\n",
       "      <td>31309500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>42.669998</td>\n",
       "      <td>42.956001</td>\n",
       "      <td>41.956001</td>\n",
       "      <td>42.189999</td>\n",
       "      <td>42.189999</td>\n",
       "      <td>14842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>175.567993</td>\n",
       "      <td>177.304001</td>\n",
       "      <td>173.240005</td>\n",
       "      <td>177.132004</td>\n",
       "      <td>177.132004</td>\n",
       "      <td>39059500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>183.800003</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>181.832001</td>\n",
       "      <td>189.983994</td>\n",
       "      <td>189.983994</td>\n",
       "      <td>70873500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>2020-06-09</td>\n",
       "      <td>188.001999</td>\n",
       "      <td>190.888000</td>\n",
       "      <td>184.785995</td>\n",
       "      <td>188.134003</td>\n",
       "      <td>188.134003</td>\n",
       "      <td>56941000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>198.376007</td>\n",
       "      <td>205.496002</td>\n",
       "      <td>196.500000</td>\n",
       "      <td>205.009995</td>\n",
       "      <td>205.009995</td>\n",
       "      <td>92817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>198.039993</td>\n",
       "      <td>203.792007</td>\n",
       "      <td>194.399994</td>\n",
       "      <td>194.567993</td>\n",
       "      <td>194.567993</td>\n",
       "      <td>79582500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1371 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "0     2014-12-31   44.618000   45.136002   44.450001   44.481998   44.481998   \n",
       "1     2015-01-02   44.574001   44.650002   42.652000   43.862000   43.862000   \n",
       "2     2015-01-05   42.910000   43.299999   41.431999   42.018002   42.018002   \n",
       "3     2015-01-06   42.012001   42.840000   40.841999   42.256001   42.256001   \n",
       "4     2015-01-07   42.669998   42.956001   41.956001   42.189999   42.189999   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1366  2020-06-05  175.567993  177.304001  173.240005  177.132004  177.132004   \n",
       "1367  2020-06-08  183.800003  190.000000  181.832001  189.983994  189.983994   \n",
       "1368  2020-06-09  188.001999  190.888000  184.785995  188.134003  188.134003   \n",
       "1369  2020-06-10  198.376007  205.496002  196.500000  205.009995  205.009995   \n",
       "1370  2020-06-11  198.039993  203.792007  194.399994  194.567993  194.567993   \n",
       "\n",
       "        Volume  \n",
       "0     11487500  \n",
       "1     23822000  \n",
       "2     26842500  \n",
       "3     31309500  \n",
       "4     14842000  \n",
       "...        ...  \n",
       "1366  39059500  \n",
       "1367  70873500  \n",
       "1368  56941000  \n",
       "1369  92817000  \n",
       "1370  79582500  \n",
       "\n",
       "[1371 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd1\n",
    "df=pd1.read_csv('TSLA_2020–04–25.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "op=dict(df.loc[10])\n",
    "for keys in op: \n",
    "    op[keys] = str(op[keys]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': '2015-01-15',\n",
       " 'Open': '38.89799880981445',\n",
       " 'High': '39.150001525878906',\n",
       " 'Low': '38.0',\n",
       " 'Close': '38.374000549316406',\n",
       " 'Adj Close': '38.374000549316406',\n",
       " 'Volume': '26082500'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting just the adjusted closing prices. This will return a Pandas DataFrame\n",
    "# The index in this DataFrame is the major index of the panel_data.\n",
    "close = df['Close']\n",
    "\n",
    "# Getting all weekdays between 01/01/2000 and 12/31/2016\n",
    "all_weekdays = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "\n",
    "# How do we align the existing prices in adj_close with our new set of dates?\n",
    "# All we need to do is reindex close using all_weekdays as the new index\n",
    "close = close.reindex(all_weekdays)\n",
    "\n",
    "# Reindexing will insert missing values (NaN) for the dates that were not present\n",
    "# in the original set. To cope with this, we can fill the missing by replacing them\n",
    "# with the latest available price for each instrument.\n",
    "close = close.fillna(method='ffill')\n",
    "print(all_weekdays)\n",
    "\n",
    "close.head(10)\n",
    "\n",
    "close.describe()\n",
    "\n",
    "# Get the MSFT timeseries. This now returns a Pandas Series object indexed by date.\n",
    "msft = close.loc[:, 'MSFT']\n",
    "\n",
    "# Calculate the 20 and 100 days moving averages of the closing prices\n",
    "short_rolling_msft = msft.rolling(window=20).mean()\n",
    "long_rolling_msft = msft.rolling(window=100).mean()\n",
    "\n",
    "# Plot everything by leveraging the very powerful matplotlib package\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "ax.plot(msft.index, msft, label='MSFT')\n",
    "ax.plot(short_rolling_msft.index, short_rolling_msft, label='20 days rolling')\n",
    "ax.plot(long_rolling_msft.index, long_rolling_msft, label='100 days rolling')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Adjusted closing price ($)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ARYAN\\anaconda3\\envs\\pro\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\ARYAN\\anaconda3\\envs\\pro\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\ARYAN\\anaconda3\\envs\\pro\\lib\\site-packages\\multitasking\\__init__.py\", line 104, in _run_via_pool\n",
      "    return callee(*args, **kwargs)\n",
      "  File \"C:\\Users\\ARYAN\\anaconda3\\envs\\pro\\lib\\site-packages\\yfinance\\multi.py\", line 188, in _download_one_threaded\n",
      "    data = _download_one(ticker, start, end, auto_adjust, back_adjust,\n",
      "  File \"C:\\Users\\ARYAN\\anaconda3\\envs\\pro\\lib\\site-packages\\yfinance\\multi.py\", line 202, in _download_one\n",
      "    return Ticker(ticker).history(period=period, interval=interval,\n",
      "  File \"C:\\Users\\ARYAN\\anaconda3\\envs\\pro\\lib\\site-packages\\yfinance\\base.py\", line 153, in history\n",
      "    _time.strptime(str(start), '%Y-%m-%d')))\n",
      "  File \"C:\\Users\\ARYAN\\anaconda3\\envs\\pro\\lib\\_strptime.py\", line 562, in _strptime_time\n",
      "    tt = _strptime(data_string, format)[0]\n",
      "  File \"C:\\Users\\ARYAN\\anaconda3\\envs\\pro\\lib\\_strptime.py\", line 349, in _strptime\n",
      "    raise ValueError(\"time data %r does not match format %r\" %\n",
      "ValueError: time data 'yahoo' does not match format '%Y-%m-%d'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ATVI', 'AYI', 'ADBE', 'AAP', 'AMD', 'AES', 'AET', 'AMG', 'AFL', 'A', 'APD', 'AKAM', 'ALK', 'ALB', 'ARE', 'ALXN', 'ALGN', 'ALLE', 'AGN', 'ADS', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'ABC', 'AME', 'AMGN', 'APH', 'ADI', 'ANDV', 'ANSS', 'ANTM', 'AON', 'APA', 'AIV', 'AAPL', 'AMAT', 'APTV', 'ADM', 'ARNC', 'AJG', 'AIZ', 'T', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'BLL', 'BAC', 'BAX', 'BDX', 'BBY', 'BIIB', 'BLK', 'HRB', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BHF', 'BMY', 'AVGO', 'CHRW', 'CA', 'COG', 'CDNS', 'CPB', 'COF', 'CAH', 'KMX', 'CCL', 'CAT', 'CBOE', 'CBRE', 'CBS', 'CELG', 'CNC', 'CNP', 'CTL', 'CERN', 'CF', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'XEC', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CTXS', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'CXO', 'COP', 'ED', 'STZ', 'GLW', 'COST', 'COTY', 'CCI', 'CSRA', 'CSX', 'CMI', 'CVS', 'DHI', 'DHR', 'DRI', 'DVA', 'DE', 'DAL', 'XRAY', 'DVN', 'DLR', 'DFS', 'DISCA', 'DISCK', 'DISH', 'DG', 'DLTR', 'D', 'DOV', 'DTE', 'DUK', 'DRE', 'DXC', 'ETFC', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'EMR', 'ETR', 'EVHC', 'EOG', 'EQT', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'RE', 'ES', 'EXC', 'EXPE', 'EXPD', 'ESRX', 'EXR', 'XOM', 'FFIV', 'FB', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FE', 'FISV', 'FLIR', 'FLS', 'FLR', 'FMC', 'FL', 'F', 'FTV', 'FBHS', 'BEN', 'FCX', 'GPS', 'GRMN', 'IT', 'GD', 'GE', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GS', 'GT', 'GWW', 'HAL', 'HBI', 'HOG', 'HIG', 'HAS', 'HCA', 'HP', 'HSIC', 'HES', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HPQ', 'HUM', 'HBAN', 'HII', 'IDXX', 'INFO', 'ITW', 'ILMN', 'INCY', 'IR', 'INTC', 'ICE', 'IBM', 'IP', 'IPG', 'IFF', 'INTU', 'ISRG', 'IVZ', 'IPGP', 'IQV', 'IRM', 'JBHT', 'JEC', 'SJM', 'JNJ', 'JCI', 'JPM', 'JNPR', 'KSU', 'K', 'KEY', 'KMB', 'KIM', 'KMI', 'KLAC', 'KSS', 'KHC', 'KR', 'LB', 'LH', 'LRCX', 'LEG', 'LEN', 'LLY', 'LNC', 'LKQ', 'LMT', 'L', 'LOW', 'LYB', 'MTB', 'MAC', 'M', 'MRO', 'MPC', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MAT', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'MET', 'MTD', 'MGM', 'MCHP', 'MU', 'MSFT', 'MAA', 'MHK', 'TAP', 'MDLZ', 'MON', 'MNST', 'MCO', 'MS', 'MSI', 'MYL', 'NDAQ', 'NOV', 'NAVI', 'NKTR', 'NTAP', 'NFLX', 'NWL', 'NFX', 'NEM', 'NWSA', 'NWS', 'NEE', 'NLSN', 'NKE', 'NI', 'NBL', 'JWN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'ORLY', 'OXY', 'OMC', 'OKE', 'ORCL', 'PCAR', 'PKG', 'PH', 'PAYX', 'PYPL', 'PNR', 'PBCT', 'PEP', 'PKI', 'PRGO', 'PFE', 'PCG', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'RL', 'PPG', 'PPL', 'PX', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PSA', 'PHM', 'PVH', 'QRVO', 'QCOM', 'PWR', 'DGX', 'RRC', 'RJF', 'RTN', 'O', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RHI', 'ROK', 'COL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SCG', 'SLB', 'STX', 'SEE', 'SRE', 'SHW', 'SPG', 'SWKS', 'SLG', 'SNA', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'SRCL', 'SYK', 'STI', 'SIVB', 'SYF', 'SNPS', 'SYY', 'TROW', 'TTWO', 'TPR', 'TGT', 'TEL', 'FTI', 'TXN', 'TXT', 'BK', 'CLX', 'COO', 'HSY', 'MOS', 'TRV', 'DIS', 'TMO', 'TIF', 'TWX', 'TJX', 'TSCO', 'TDG', 'TRIP', 'FOXA', 'FOX', 'TSN', 'USB', 'UDR', 'ULTA', 'UAA', 'UA', 'UNP', 'UAL', 'UNH', 'UPS', 'URI', 'UTX', 'UHS', 'UNM', 'VFC', 'VLO', 'VAR', 'VTR', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VIAB', 'V', 'VNO', 'VMC', 'WMT', 'WBA', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WDC', 'WU', 'WRK', 'WY', 'WHR', 'WMB', 'WLTW', 'WYNN', 'XEL', 'XRX', 'XLNX', 'XL', 'XYL', 'YUM', 'ZBH', 'ZION', 'ZTS']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18032/1712476077.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mpanel_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data2//'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mik\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mfetchpriceandsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18032/1712476077.py\u001b[0m in \u001b[0;36mfetchpriceandsave\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# User pandas_reader.data.DataReader to load the desired data. As simple as that.\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mik\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtickers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mpanel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mik\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'yahoo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m#print(panel_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pro\\lib\\site-packages\\yfinance\\multi.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(tickers, start, end, actions, threads, group_by, auto_adjust, back_adjust, progress, period, show_errors, interval, prepost, proxy, rounding, timeout, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m                                    rounding=rounding, timeout=timeout)\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_DFS\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0m_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;31m# download synchronously\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#final fetching price from all\n",
    "\n",
    "\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# We would like all available data from 01/01/2000 until 12/31/2016.\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2020-04-25'\n",
    "df1=pd.read_csv('fortune500.csv')\n",
    "tickers = list(df1['Symbol'])\n",
    "print(tickers)\n",
    "def fetchpriceandsave():\n",
    "    \n",
    "# User pandas_reader.data.DataReader to load the desired data. As simple as that.\\\n",
    "    for ik in tickers:\n",
    "        panel_data = data.DataReader(ik,'yahoo', start_date, end_date)\n",
    "\n",
    "        #print(panel_data)\n",
    "\n",
    "        panel_data.to_csv('data2//'+ik+'.csv')\n",
    "\n",
    "fetchpriceandsave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://in.finance.yahoo.com/quote/amzn\n",
      "2410.22\n",
      "2,417.00\n",
      " data-test=\"FIFTY_TWO_WK_RANGE-value\">1,626.03 - 2,461.00</td></tr><tr class=\"Bxz(bb) Bdbw(1px) Bdbs(s) Bdc($seperatorColor) H(36px)\" data-reactid=\"68\"><td class=\"C($primaryColor) W(51%)\" data-reactid=\"69\"><span data-reactid=\"70\">Volume\n",
      "completed...\n"
     ]
    }
   ],
   "source": [
    "### Extract from Yahoo Link ###\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests_html\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "#import unidecode\n",
    "ticker_list1=[\"amzn\"]\n",
    "for ticker in ticker_list1:\n",
    "    url = 'https://in.finance.yahoo.com/quote/' + ticker\n",
    "    print(url)\n",
    "    session = requests_html.HTMLSession()\n",
    "    r = session.get(url)\n",
    "    content = BeautifulSoup(r.content, 'html')\n",
    "    try:\n",
    "        price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #print(str(content).split('data-reactid=\"47\"'))\n",
    "        openprice = str(content).split('data-reactid=\"49\"')[3].split('</span>')[0].replace('>','')\n",
    "        rangeobt = str(content).split('data-reactid=\"67\"')[2].split('</span>')[0]\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "    except IndexError as e:\n",
    "        price = 0.00\n",
    "    price = price or \"0\"\n",
    "    try:\n",
    "        price = float(price.replace(',',''))\n",
    "    except ValueError as e:\n",
    "        price = 0.00\n",
    "    time.sleep(1)\n",
    "   \n",
    "    print( price)\n",
    "    print(openprice)\n",
    "    print(rangeobt)\n",
    "        #cursor.execute(_SQL, (unidecode.unidecode(ticker[0]), price, unidecode.unidecode(ticker[1]), unidecode.unidecode(ticker[2]), unidecode.unidecode(ticker[3])))\n",
    "print('completed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests_html\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "def fetchcurrentmarketprice(stock):\n",
    "    stock1=stock\n",
    "    #for ticker in ticker_list1:\n",
    "    url = 'https://in.finance.yahoo.com/quote/' + stock1\n",
    "    print(url)\n",
    "    session = requests_html.HTMLSession()\n",
    "    r = session.get(url)\n",
    "    content = BeautifulSoup(r.content, 'html')\n",
    "    try:\n",
    "        price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #print(str(content).split('data-reactid=\"47\"'))\n",
    "        openprice = str(content).split('data-reactid=\"49\"')[3].split('</span>')[0].replace('>','')\n",
    "        rangeobt = str(content).split('data-reactid=\"67\"')[2].split('</span>')[0]\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "    except IndexError as e:\n",
    "        price = 0.00\n",
    "        price = price or \"0\"\n",
    "    try:\n",
    "        price = float(price.replace(',',''))\n",
    "    except ValueError as e:\n",
    "        price = 0.00\n",
    "        time.sleep(1)\n",
    "   \n",
    "    print( price)\n",
    "    print(openprice)\n",
    "    print(rangeobt)\n",
    "        #cursor.execute(_SQL, (unidecode.unidecode(ticker[0]), price, unidecode.unidecode(ticker[1]), unidecode.unidecode(ticker[2]), unidecode.unidecode(ticker[3])))\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://in.finance.yahoo.com/quote/amzn\n",
      "2410.22\n",
      "2,417.00\n",
      " data-test=\"FIFTY_TWO_WK_RANGE-value\">1,626.03 - 2,461.00</td></tr><tr class=\"Bxz(bb) Bdbw(1px) Bdbs(s) Bdc($seperatorColor) H(36px)\" data-reactid=\"68\"><td class=\"C($primaryColor) W(51%)\" data-reactid=\"69\"><span data-reactid=\"70\">Volume\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2410.22"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetchcurrentmarketprice('amzn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for aapl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\.conda\\envs\\project\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'finance.yahoo.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing http://finance.yahoo.com/quote/aapl?p=aapl\n",
      "OrderedDict([('', '303.75'), ('1y Target Est', 303.75), ('EPS (TTM)', 12.595), ('Earnings Date', '2020-04-30'), ('ticker', 'aapl'), ('url', 'http://finance.yahoo.com/quote/aapl?p=aapl')])\n",
      "Writing data to output file\n"
     ]
    }
   ],
   "source": [
    "from lxml import html  \n",
    "import requests\n",
    "from time import sleep\n",
    "import json\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "from time import sleep\n",
    "\n",
    "def parse(ticker):\n",
    "\turl = \"http://finance.yahoo.com/quote/%s?p=%s\"%(ticker,ticker)\n",
    "    #print(url)\n",
    "\tresponse = requests.get(url, verify=False)\n",
    "\tprint (\"Parsing %s\"%(url))\n",
    "\tsleep(4)\n",
    "\tparser = html.fromstring(response.text)\n",
    "\tsummary_table = parser.xpath('//div[contains(@data-test,\"summary-table\")]//tr')\n",
    "\tsummary_data = OrderedDict()\n",
    "\tother_details_json_link = \"https://query2.finance.yahoo.com/v10/finance/quoteSummary/{0}?formatted=true&lang=en-US&region=US&modules=summaryProfile%2CfinancialData%2CrecommendationTrend%2CupgradeDowngradeHistory%2Cearnings%2CdefaultKeyStatistics%2CcalendarEvents&corsDomain=finance.yahoo.com\".format(ticker)\n",
    "\tsummary_json_response = requests.get(other_details_json_link)\n",
    "\ttry:\n",
    "\t\tjson_loaded_summary =  json.loads(summary_json_response.text)\n",
    "\t\ty_Target_Est = json_loaded_summary[\"quoteSummary\"][\"result\"][0][\"financialData\"][\"targetMeanPrice\"]['raw']\n",
    "\t\tearnings_list = json_loaded_summary[\"quoteSummary\"][\"result\"][0][\"calendarEvents\"]['earnings']\n",
    "\t\teps = json_loaded_summary[\"quoteSummary\"][\"result\"][0][\"defaultKeyStatistics\"][\"trailingEps\"]['raw']\n",
    "\t\tdatelist = []\n",
    "\t\tfor i in earnings_list['earningsDate']:\n",
    "\t\t\tdatelist.append(i['fmt'])\n",
    "\t\tearnings_date = ' to '.join(datelist)\n",
    "\t\tfor table_data in summary_table:\n",
    "\t\t\traw_table_key = table_data.xpath('.//td[contains(@class,\"C(black)\")]//text()')\n",
    "\t\t\traw_table_value = table_data.xpath('.//td[contains(@class,\"Ta(end)\")]//text()')\n",
    "\t\t\ttable_key = ''.join(raw_table_key).strip()\n",
    "\t\t\ttable_value = ''.join(raw_table_value).strip()\n",
    "\t\t\tsummary_data.update({table_key:table_value})\n",
    "\t\tsummary_data.update({'1y Target Est':y_Target_Est,'EPS (TTM)':eps,'Earnings Date':earnings_date,'ticker':ticker,'url':url})\n",
    "\t\treturn summary_data\n",
    "\texcept:\n",
    "\t\tprint (\"Failed to parse json response\")\n",
    "\t\treturn {\"error\":\"Failed to parse json response\"}\n",
    "\t\t\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "\tticker = \"aapl\"\n",
    "\tprint (\"Fetching data for %s\"%(ticker))\n",
    "\tscraped_data = parse(ticker)\n",
    "\tprint(scraped_data)\n",
    "\tprint (\"Writing data to output file\")\n",
    "\twith open('%s-summary.json'%(ticker),'w') as fp:\n",
    "\t\tjson.dump(scraped_data,fp,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "def fetchpriceandsave(val):\n",
    "    start_date = '2020-04-25'\n",
    "    end_date = '2020-04-26'    \n",
    "# User pandas_reader.data.DataReader to load the desired data. As simple as that.\\\n",
    "    #for ik in tickers:\n",
    "    panel_data = data.DataReader(val, start_date, end_date)\n",
    "\n",
    "        #print(panel_data)\n",
    "\n",
    "    panel_data.to_csv(val+'.csv')\n",
    "\n",
    "fetchpriceandsave('amzn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
