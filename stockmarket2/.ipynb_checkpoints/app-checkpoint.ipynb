{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 10013] An attempt was made to access a socket in a way forbidden by its access permissions",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-73dc7a59397e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[1;31m#app.run('0.0.0.0')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 478\u001b[1;33m     \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'0.0.0.0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\flask\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, host, port, debug, load_dotenv, **options)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m             \u001b[0mrun_simple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m             \u001b[1;31m# reset the first request information if the development server\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\werkzeug\\serving.py\u001b[0m in \u001b[0;36mrun_simple\u001b[1;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[0mrun_with_reloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_files\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreloader_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreloader_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m         \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\werkzeug\\serving.py\u001b[0m in \u001b[0;36minner\u001b[1;34m()\u001b[0m\n\u001b[0;32m    994\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mLookupError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m             \u001b[0mfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m         srv = make_server(\n\u001b[0m\u001b[0;32m    997\u001b[0m             \u001b[0mhostname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\werkzeug\\serving.py\u001b[0m in \u001b[0;36mmake_server\u001b[1;34m(host, port, app, threaded, processes, request_handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[0;32m    845\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cannot have a multithreaded and multi process server.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mthreaded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m         return ThreadedWSGIServer(\n\u001b[0m\u001b[0;32m    848\u001b[0m             \u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpassthrough_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\site-packages\\werkzeug\\serving.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, host, port, app, handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddress_family\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0maf_unix\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m         \u001b[0mHTTPServer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserver_address\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\socketserver.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, server_address, RequestHandlerClass, bind_and_activate)\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbind_and_activate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_bind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_activate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\http\\server.py\u001b[0m in \u001b[0;36mserver_bind\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mserver_bind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;34m\"\"\"Override server_bind to store the server name.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0msocketserver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCPServer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_bind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfqdn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Project\\lib\\socketserver.py\u001b[0m in \u001b[0;36mserver_bind\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_reuse_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOL_SOCKET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSO_REUSEADDR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_address\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetsockname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 10013] An attempt was made to access a socket in a way forbidden by its access permissions"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask import render_template,request\n",
    "from datetime import time\n",
    "import pandas as pd1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from flask_jsonpify import jsonpify\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "#importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "#to plot within notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from flask import jsonify \n",
    "\n",
    "from yahoo_fin import stock_info as si\n",
    "\n",
    "def getpriceinfo(symbol):\n",
    "    lp=si.get_live_price(symbol)\n",
    "\n",
    "    \n",
    " \n",
    "    #print(si.get_day_most_active())\n",
    " \n",
    "    # get biggest gainers\n",
    "    #print(si.get_day_gainers())\n",
    " \n",
    "    # get worst performers\n",
    "    #print(si.get_day_losers())\n",
    "    return lp\n",
    "\n",
    "def getqoutetable(symbol):\n",
    "    \n",
    "\n",
    "    qt=si.get_quote_table(symbol, dict_result = False)\n",
    " \n",
    "    #print(si.get_day_most_active())\n",
    " \n",
    "    # get biggest gainers\n",
    "    #print(si.get_day_gainers())\n",
    " \n",
    "    # get worst performers\n",
    "    #print(si.get_day_losers())\n",
    "    return qt\n",
    "\n",
    "# function to calculate percentage difference considering baseValue as 100%\n",
    "def percentageChange(baseValue, currentValue):\n",
    "    return((float(currentValue)-baseValue) / abs(baseValue)) *100.00\n",
    "\n",
    "# function to get the actual value using baseValue and percentage\n",
    "def reversePercentageChange(baseValue, percentage):\n",
    "    return float(baseValue) + float(baseValue * percentage / 100.00)\n",
    "\n",
    "# function to transform a list of values into the list of percentages. For calculating percentages for each element in the list\n",
    "# the base is always the previous element in the list.\n",
    "def transformToPercentageChange(x):\n",
    "    baseValue = x[0]\n",
    "    x[0] = 0\n",
    "    for i in range(1,len(x)):\n",
    "        pChange = percentageChange(baseValue,x[i])\n",
    "        baseValue = x[i]\n",
    "        x[i] = pChange\n",
    "\n",
    "# function to transform a list of percentages to the list of actual values. For calculating actual values for each element in the list\n",
    "# the base is always the previous calculated element in the list.\n",
    "def reverseTransformToPercentageChange(baseValue, x):\n",
    "    x_transform = []\n",
    "    for i in range(0,len(x)):\n",
    "        value = reversePercentageChange(baseValue,x[i])\n",
    "        baseValue = value\n",
    "        x_transform.append(value)\n",
    "    return x_transform\n",
    "\n",
    "#read the data file\n",
    "def predictpriceofdata(stockname):\n",
    "    df = pd.read_csv('data\\\\'+stockname+'.csv')\n",
    "# store the first element in the series as the base value for future use.\n",
    "    baseValue = df['Close'][0]\n",
    "\n",
    "# create a new dataframe which is then transformed into relative percentages\n",
    "    data = df.sort_index(ascending=True, axis=0)\n",
    "    new_data = pd.DataFrame(index=range(0,len(df)),columns=['Date', 'Close'])\n",
    "    for i in range(0,len(data)):\n",
    "        new_data['Date'][i] = data['Date'][i]\n",
    "        new_data['Close'][i] = data['Close'][i]\n",
    "\n",
    "# transform the 'Close' series into relative percentages\n",
    "    transformToPercentageChange(new_data['Close'])\n",
    "\n",
    "# set Dat column as the index\n",
    "    new_data.index = new_data.Date\n",
    "    new_data.drop('Date', axis=1, inplace=True)\n",
    "\n",
    "# create train and test sets\n",
    "    dataset = new_data.values\n",
    "    train, valid = train_test_split(dataset, train_size=0.99, test_size=0.01, shuffle=False)\n",
    "\n",
    "# convert dataset into x_train and y_train.\n",
    "# prediction_window_size is the size of days windows which will be considered for predicting a future value.\n",
    "    prediction_window_size = 60\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(prediction_window_size,len(train)):\n",
    "        x_train.append(dataset[i-prediction_window_size:i,0])\n",
    "        y_train.append(dataset[i,0])\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\n",
    "\n",
    "##################################################################################################\n",
    "# create and fit the LSTM network\n",
    "# Initialising the RNN\n",
    "    model = Sequential()\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "    model.add(LSTM(units = 50))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "# Adding the output layer\n",
    "    model.add(Dense(units = 1))\n",
    "# Compiling the RNN\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "    model.fit(x_train, y_train, epochs = 1, batch_size = 1000)\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "#predicting future values, using past 60 from the train data\n",
    "# for next 10 yrs total_prediction_days is set to 3650 days\n",
    "    total_prediction_days = 3650\n",
    "    inputs = new_data[-total_prediction_days:].values\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "\n",
    "# create future predict list which is a two dimensional list of values.\n",
    "# the first dimension is the total number of future days\n",
    "# the second dimension is the list of values of prediction_window_size size\n",
    "    X_predict = []\n",
    "    for i in range(prediction_window_size,inputs.shape[0]):\n",
    "        X_predict.append(inputs[i-prediction_window_size:i,0])\n",
    "    X_predict = np.array(X_predict)\n",
    "\n",
    "# predict the future\n",
    "    X_predict = np.reshape(X_predict, (X_predict.shape[0],X_predict.shape[1],1))\n",
    "    future_closing_price = model.predict(X_predict)\n",
    "\n",
    "    train, valid = train_test_split(new_data, train_size=0.99, test_size=0.01, shuffle=False)\n",
    "    date_index = pd.to_datetime(train.index)\n",
    "\n",
    "#converting dates into number of days as dates cannot be passed directly to any regression model\n",
    "    x_days = (date_index - pd.to_datetime('1970-01-01')).days\n",
    "\n",
    "# we are doing prediction for next 5 years hence prediction_for_days is set to 1500 days.\n",
    "    prediction_for_days = 300\n",
    "    future_closing_price = future_closing_price[:prediction_for_days]\n",
    "\n",
    "# create a data index for future dates\n",
    "    x_predict_future_dates = np.asarray(pd.RangeIndex(start=x_days[-1] + 1, stop=x_days[-1] + 1 + (len(future_closing_price))))\n",
    "    future_date_index = pd.to_datetime(x_predict_future_dates, origin='1970-01-01', unit='D')\n",
    "\n",
    "# transform a list of relative percentages to the actual values\n",
    "    train_transform = reverseTransformToPercentageChange(baseValue, train['Close'])\n",
    "\n",
    "# for future dates the base value the the value of last element from the training set.\n",
    "    baseValue = train_transform[-1]\n",
    "    valid_transform = reverseTransformToPercentageChange(baseValue, valid['Close'])\n",
    "    future_closing_price_transform = reverseTransformToPercentageChange(baseValue, future_closing_price)\n",
    "\n",
    "# recession peak date is the date on which the index is at the bottom most position.\n",
    "    recessionPeakDate =  future_date_index[future_closing_price_transform.index(min(future_closing_price_transform))]\n",
    "    minCloseInFuture = min(future_closing_price_transform);\n",
    "    print(\"The stock market will reach to its lowest bottom on\", recessionPeakDate)\n",
    "    print(\"The lowest index the stock market will fall to is \", minCloseInFuture)\n",
    "\n",
    "# plot the graphs\n",
    "    plt.figure(figsize=(16,8))\n",
    "    df_x = pd.to_datetime(new_data.index)\n",
    "    plt.plot(date_index,train_transform, label='Close Price History')\n",
    "    plt.plot(future_date_index,future_closing_price_transform, label='Predicted Close')\n",
    "\n",
    "# set the title of the graph\n",
    "    plt.suptitle('Stock Market Predictions', fontsize=16)\n",
    "\n",
    "# set the title of the graph window\n",
    "    fig = plt.gcf()\n",
    "    fig.canvas.set_window_title('Stock Market Predictions')\n",
    "\n",
    "#display the legends\n",
    "    plt.legend()\n",
    "\n",
    "#display the graph\n",
    "    plt.show()\n",
    "    \n",
    "    dictofdateandprice={}\n",
    "    \n",
    "    for i in range(38,50):\n",
    "        dictofdateandprice[str(future_date_index[i])]=future_closing_price_transform[i]\n",
    "    return jsonify(dictofdateandprice)\n",
    "def fetchcurrentmarketprice(stock):\n",
    "    stock1=stock\n",
    "    #for ticker in ticker_list1:\n",
    "    url = 'https://in.finance.yahoo.com/quote/' + stock1\n",
    "    print(url)\n",
    "    session = requests_html.HTMLSession()\n",
    "    r = session.get(url)\n",
    "    content = BeautifulSoup(r.content, 'html')\n",
    "    try:\n",
    "        price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #print(str(content).split('data-reactid=\"47\"'))\n",
    "        openprice = str(content).split('data-reactid=\"49\"')[3].split('</span>')[0].replace('>','')\n",
    "        rangeobt = str(content).split('data-reactid=\"67\"')[2].split('</span>')[0]\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "    except IndexError as e:\n",
    "        price = 0.00\n",
    "        price = price or \"0\"\n",
    "    try:\n",
    "        price = float(price.replace(',',''))\n",
    "    except ValueError as e:\n",
    "        price = 0.00\n",
    "        time.sleep(1)\n",
    "   \n",
    "    print( price)\n",
    "    print(openprice)\n",
    "    print(rangeobt)\n",
    "        #cursor.execute(_SQL, (unidecode.unidecode(ticker[0]), price, unidecode.unidecode(ticker[1]), unidecode.unidecode(ticker[2]), unidecode.unidecode(ticker[3])))\n",
    "    return price\n",
    "\n",
    "\n",
    "\n",
    "#urltofetch='https://www.usatoday.com/story/money/2020/04/22/amazon-doing-free-deliveries-food-banks-during-coronavirus-emergency/2997254001/'\n",
    "\n",
    "#alldata=parsenews(urltofetch)\n",
    "#print(alldata)\n",
    "\n",
    "#Python program to scrape website  \n",
    "#and save quotes from website \n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import csv \n",
    "import re\n",
    "\n",
    "def callingnews(query):\n",
    "\n",
    "    URL = \"https://www.usatoday.com/search/?q=\"+query\n",
    "    r = requests.get(URL) \n",
    "#print(r)\n",
    "  \n",
    "    soup = BeautifulSoup(r.content, 'html.parser') \n",
    "#print(soup)\n",
    "    quotes=[]  # a list to store quotes \n",
    "  \n",
    "\n",
    "    table1 = soup.find_all('a', attrs = {'class':'gnt_se_a gnt_se_a__hd gnt_se_a__hi'}) \n",
    "    #print(table1)\n",
    "\n",
    "#table13 = table11.get_text()\n",
    "#print(table13) \n",
    "\n",
    "    table11 = soup.find_all('div', attrs = {'class':'gnt_pr'}) \n",
    "    #print(table11)\n",
    "    datalist=[]\n",
    "    linksdata=[]\n",
    "#print(table11)\n",
    "    for ik in table1:\n",
    "        datalist.append(ik.get_text())\n",
    "        print(ik.get_text())\n",
    "\n",
    "    pos=0\n",
    "    listtocheck=[]\n",
    "    for ik in table1:\n",
    "        links = re.findall(\"href=[\\\"\\'](.*?)[\\\"\\']\", str(ik))\n",
    "        linksdata.append('https://www.usatoday.com'+links[0])\n",
    "        if 'story' not in links[0]:\n",
    "            listtocheck.append(pos)\n",
    "        pos+=1\n",
    "        print(links)\n",
    "\n",
    "    print(\"list check is \",listtocheck)\n",
    "\n",
    "    for ij in range(len(listtocheck)):\n",
    "        print(ij)\n",
    "        datalist.pop(ij)\n",
    "        linksdata.pop(ij)\n",
    "    #print(listtocheck[ij])\n",
    "\n",
    "    print(len(datalist))\n",
    "    print(len(linksdata))\n",
    "    return datalist,linksdata\n",
    "\n",
    "\n",
    "#df\n",
    "df1=pd1.read_csv('fortune500.csv')\n",
    "df=pd.DataFrame()\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route(\"/parsenews\")\n",
    "def parsenews(): \n",
    "    newsinfo = request.args.get('msg')\n",
    "    URL =newsinfo.rstrip().lstrip().strip()# \"https://www.hindustantimes.com/delhi-news/protest-at-delhi-s-jama-masjid-against-citizenship-act-4-metro-stations-closed-in-area/story-q7vKj5IUdIKMExw5eGBfxI.html\"\n",
    "    #URL =\"https://www.hindustantimes.com/delhi-news/protest-at-delhi-s-jama-masjid-against-citizenship-act-4-metro-stations-closed-in-area/story-q7vKj5IUdIKMExw5eGBfxI.html\"\n",
    "    #print repr(URL)\n",
    "    r = requests.get(URL) \n",
    "    #print(r)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser') \n",
    "  \n",
    "    quotes=[]  # a list to store quotes \n",
    "  \n",
    "    table = soup.find('div', attrs = {'class':'gnt_ar_b'}) \n",
    "    #print(table)\n",
    "    alltestdata='<a href=\\''+URL+'\\' target=\"_blank\" >'+URL+'</a>'+'<br>'\n",
    "    print(alltestdata)\n",
    "    try:\n",
    "        table1 = table.find_all('p')\n",
    "        \n",
    "        for row in table.find_all('p'):\n",
    "            quote = {} \n",
    "            quote['data'] = row.text \n",
    "            alltestdata=alltestdata+row.text+\" \"\n",
    "            quotes.append(quote)\n",
    "    except:\n",
    "        alltestdata='<a href=\\''+URL+'\\' target=\"_blank\" >'+URL+'</a>'+'<br>'\n",
    "    #print(alltestdata)\n",
    "    print(alltestdata)\n",
    "    return alltestdata\n",
    "\n",
    "@app.route(\"/searchforcompany\")\n",
    "def searchforcompany():\n",
    "    global df\n",
    "    legend = 'Stock Price data'\n",
    "    company = request.args.get('company')\n",
    "    dfop=df1.loc[df1['Name'] == company]\n",
    "    op1=str(dfop['Symbol'].iloc[0])\n",
    "    print(op1)\n",
    "    df=pd1.read_csv('data//'+op1+'.csv')\n",
    "    temperatures = list(df['Close'])\n",
    "    times = list(df['Date'])\n",
    "    \n",
    "    datalist,linksdata=callingnews(company)\n",
    "    dictis={}\n",
    "    for ims in range(len(datalist)):\n",
    "        dictis[datalist[ims]]=linksdata[ims]\n",
    "        \n",
    "    print(dictis)\n",
    "    urlofsite='https://www.usatoday.com'\n",
    "    io=0\n",
    "    return render_template('line_chart.html',dictdata=dictis,links=linksdata,news=datalist, values=temperatures, labels=times, legend=legend,stockname=company,symbolis=op1)\n",
    "    #return op1\n",
    "\n",
    "@app.route(\"/futurepriceprediction\")\n",
    "def futurepriceprediction():\n",
    "    companySymbol = request.args.get('msg')\n",
    "    dictis=predictpriceofdata(companySymbol)\n",
    "    #print('price is')\n",
    "    print(dictis)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return dictis\n",
    "\n",
    "    \n",
    "    \n",
    "@app.route(\"/fetchprice\")\n",
    "def fetchprice():\n",
    "    company = request.args.get('msg')\n",
    "    priceis=getpriceinfo(company)#'1211'#fetchcurrentmarketprice(company)\n",
    "    print('price is')\n",
    "    print(priceis)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return str(priceis)\n",
    "\n",
    "\n",
    "@app.route(\"/getqoutetableval\")\n",
    "def getqoutetableval():\n",
    "    company = request.args.get('msg')\n",
    "    print('company for qoute '+company)\n",
    "    qoute=getqoutetable(company)#'1211'#fetchcurrentmarketprice(company)\n",
    "    print('qoute is')\n",
    "    print(qoute)\n",
    "    df_list = qoute.values.tolist()\n",
    "    alldata=''\n",
    "    for ik in range(len(df_list)):\n",
    "        alldata=alldata+str(df_list[ik][0])+\" :- \"+str(df_list[ik][1])+\"<br>\\n\"\n",
    "    #JSONP_data = jsonpify(df_list)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return alldata\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    temperatures = dict(df1['Name'])\n",
    "    sendingcompaniesinfo={}\n",
    "    for keys in temperatures: \n",
    "        temperatures[keys] = str(temperatures[keys]) \n",
    "        sendingcompaniesinfo[temperatures[keys]]='null'\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return render_template('searching.html', values=sendingcompaniesinfo)\n",
    "\n",
    "@app.route(\"/simple_chart\")\n",
    "def chart():\n",
    "    legend = 'Monthly Data'\n",
    "    labels = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\"]\n",
    "    values = [10, 9, 8, 7, 6, 4, 7, 8]\n",
    "    return render_template('chart.html', values=values, labels=labels, legend=legend)\n",
    "\n",
    "\n",
    "@app.route(\"/line_chart\")\n",
    "def line_chart():\n",
    "    legend = 'Temperatures'\n",
    "    temperatures = list(df['Close'])\n",
    "    times = list(df['Date'])\n",
    "    return render_template('line_chart.html', values=temperatures, labels=times, legend=legend)\n",
    "\n",
    "@app.route(\"/price\")\n",
    "def price():\n",
    "    global df\n",
    "    userText = request.args.get('msg')\n",
    "    print(userText)\n",
    "    op=dict(df.iloc[int(userText)])#tuple(list(df.iloc[int(userText)]))\n",
    "    print(op)\n",
    "    #for dicts in test_list: \n",
    "    for keys in op: \n",
    "        op[keys] = str(op[keys]) \n",
    "    return op\n",
    "\n",
    "@app.route(\"/time_chart\")\n",
    "def time_chart():\n",
    "    legend = 'Temperatures'\n",
    "    temperatures = [73.7, 73.4, 73.8, 72.8, 68.7, 65.2,\n",
    "                    61.8, 58.7, 58.2, 58.3, 60.5, 65.7,\n",
    "                    70.2, 71.4, 71.2, 70.9, 71.3, 71.1]\n",
    "    times = [time(hour=11, minute=14, second=15),\n",
    "             time(hour=11, minute=14, second=30),\n",
    "             time(hour=11, minute=14, second=45),\n",
    "             time(hour=11, minute=15, second=00),\n",
    "             time(hour=11, minute=15, second=15),\n",
    "             time(hour=11, minute=15, second=30),\n",
    "             time(hour=11, minute=15, second=45),\n",
    "             time(hour=11, minute=16, second=00),\n",
    "             time(hour=11, minute=16, second=15),\n",
    "             time(hour=11, minute=16, second=30),\n",
    "             time(hour=11, minute=16, second=45),\n",
    "             time(hour=11, minute=17, second=00),\n",
    "             time(hour=11, minute=17, second=15),\n",
    "             time(hour=11, minute=17, second=30),\n",
    "             time(hour=11, minute=17, second=45),\n",
    "             time(hour=11, minute=18, second=00),\n",
    "             time(hour=11, minute=18, second=15),\n",
    "             time(hour=11, minute=18, second=30)]\n",
    "    return render_template('time_chart.html', values=temperatures, labels=times, legend=legend)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #app.run('0.0.0.0')\n",
    "    app.run('0.0.0.0',port=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask_jsonpify import jsonpify\n",
    "qoute=getqoutetable('amzn')#'1211'#fetchcurrentmarketprice(company)\n",
    "#print('qoute is')\n",
    "#print(qoute)\n",
    "df_list = qoute.values.tolist()\n",
    "print(df_list)\n",
    "print(df_list[0][0])\n",
    "print(df_list[0][1])\n",
    "print(df_list[1][0])\n",
    "print(df_list[2][0])\n",
    "\n",
    "alldata=''\n",
    "for ik in range(len(df_list)):\n",
    "    alldata=alldata+str(df_list[ik][0])+str(df_list[ik][1])+\"\\n\"\n",
    "\n",
    "print(alldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "[2021-03-15 19:07:09,018] ERROR in app: Exception on /time_chart [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sumit\\anaconda3\\envs\\Project\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Sumit\\anaconda3\\envs\\Project\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Sumit\\anaconda3\\envs\\Project\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Sumit\\anaconda3\\envs\\Project\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Sumit\\anaconda3\\envs\\Project\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Sumit\\anaconda3\\envs\\Project\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-68-5071f7813f16>\", line 337, in time_chart\n",
      "    times = [(time(hour=11, minute=14, second=15),\n",
      "TypeError: 'module' object is not callable\n",
      "127.0.0.1 - - [15/Mar/2021 19:07:09] \"\u001b[35m\u001b[1mGET /time_chart HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperatures\n",
      "[73.7, 73.4, 73.8, 72.8, 68.7, 65.2, 61.8, 58.7, 58.2, 58.3, 60.5, 65.7, 70.2, 71.4, 71.2, 70.9, 71.3, 71.1]\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask import render_template,request\n",
    "from datetime import time\n",
    "import pandas as pd1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from flask_jsonpify import jsonpify\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "#from datetime import timedelta\n",
    "import time\n",
    "from flask_wtf import Form\n",
    "from wtforms.fields.html5 import DateField\n",
    "#importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#to plot within notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from flask import jsonify \n",
    "\n",
    "from yahoo_fin import stock_info as si\n",
    "\n",
    "def getpriceinfo(symbol):\n",
    "    lp=si.get_live_price(symbol)\n",
    "\n",
    "    \n",
    " \n",
    "    #print(si.get_day_most_active())\n",
    " \n",
    "    # get biggest gainers\n",
    "    #print(si.get_day_gainers())\n",
    " \n",
    "    # get worst performers\n",
    "    #print(si.get_day_losers())\n",
    "    return lp\n",
    "\n",
    "def getqoutetable(symbol):\n",
    "    \n",
    "\n",
    "    qt=si.get_quote_table(symbol, dict_result = False)\n",
    " \n",
    "    #print(si.get_day_most_active())\n",
    " \n",
    "    # get biggest gainers\n",
    "    #print(si.get_day_gainers())\n",
    " \n",
    "    # get worst performers\n",
    "    #print(si.get_day_losers())\n",
    "    return qt\n",
    "\n",
    "# function to calculate percentage difference considering baseValue as 100%\n",
    "def percentageChange(baseValue, currentValue):\n",
    "    return((float(currentValue)-baseValue) / abs(baseValue)) *100.00\n",
    "\n",
    "# function to get the actual value using baseValue and percentage\n",
    "def reversePercentageChange(baseValue, percentage):\n",
    "    return float(baseValue) + float(baseValue * percentage / 100.00)\n",
    "\n",
    "# function to transform a list of values into the list of percentages. For calculating percentages for each element in the list\n",
    "# the base is always the previous element in the list.\n",
    "def transformToPercentageChange(x):\n",
    "    baseValue = x[0]\n",
    "    x[0] = 0\n",
    "    for i in range(1,len(x)):\n",
    "        pChange = percentageChange(baseValue,x[i])\n",
    "        baseValue = x[i]\n",
    "        x[i] = pChange\n",
    "\n",
    "# function to transform a list of percentages to the list of actual values. For calculating actual values for each element in the list\n",
    "# the base is always the previous calculated element in the list.\n",
    "def reverseTransformToPercentageChange(baseValue, x):\n",
    "    x_transform = []\n",
    "    for i in range(0,len(x)):\n",
    "        value = reversePercentageChange(baseValue,x[i])\n",
    "        baseValue = value\n",
    "        x_transform.append(value)\n",
    "    return x_transform\n",
    "\n",
    "#read the data file\n",
    "def predictpriceofdata(stockname):\n",
    "    \n",
    "\n",
    "# convert dataset into x_train and y_train.\n",
    "# prediction_window_size is the size of days windows which will be considered for predicting a future value.\n",
    "    \n",
    "    dictofdateandprice={}\n",
    "    \n",
    "    for i in range(38,50):\n",
    "        dictofdateandprice[str(future_date_index[i])]=1000\n",
    "    return jsonify(dictofdateandprice)\n",
    "def fetchcurrentmarketprice(stock):\n",
    "    stock1=stock\n",
    "    #for ticker in ticker_list1:\n",
    "    url = 'https://in.finance.yahoo.com/quote/' + stock1\n",
    "    print(url)\n",
    "    session = requests_html.HTMLSession()\n",
    "    r = session.get(url)\n",
    "    content = BeautifulSoup(r.content, 'html')\n",
    "    try:\n",
    "        price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #print(str(content).split('data-reactid=\"47\"'))\n",
    "        openprice = str(content).split('data-reactid=\"49\"')[3].split('</span>')[0].replace('>','')\n",
    "        rangeobt = str(content).split('data-reactid=\"67\"')[2].split('</span>')[0]\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "    except IndexError as e:\n",
    "        price = 0.00\n",
    "        price = price or \"0\"\n",
    "    try:\n",
    "        price = float(price.replace(',',''))\n",
    "    except ValueError as e:\n",
    "        price = 0.00\n",
    "        time.sleep(1)\n",
    "   \n",
    "    print( price)\n",
    "    print(openprice)\n",
    "    print(rangeobt)\n",
    "        #cursor.execute(_SQL, (unidecode.unidecode(ticker[0]), price, unidecode.unidecode(ticker[1]), unidecode.unidecode(ticker[2]), unidecode.unidecode(ticker[3])))\n",
    "    return price\n",
    "\n",
    "\n",
    "\n",
    "#urltofetch='https://www.usatoday.com/story/money/2020/04/22/amazon-doing-free-deliveries-food-banks-during-coronavirus-emergency/2997254001/'\n",
    "\n",
    "#alldata=parsenews(urltofetch)\n",
    "#print(alldata)\n",
    "\n",
    "#Python program to scrape website  \n",
    "#and save quotes from website \n",
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import csv \n",
    "import re\n",
    "from datetime import date, timedelta\n",
    "\n",
    "def callingnews(query):\n",
    "\n",
    "    URL = \"https://www.usatoday.com/search/?q=\"+query\n",
    "    r = requests.get(URL) \n",
    "#print(r)\n",
    "  \n",
    "    soup = BeautifulSoup(r.content, 'html.parser') \n",
    "#print(soup)\n",
    "    quotes=[]  # a list to store quotes \n",
    "  \n",
    "\n",
    "    table1 = soup.find_all('a', attrs = {'class':'gnt_se_a gnt_se_a__hd gnt_se_a__hi'}) \n",
    "    #print(table1)\n",
    "\n",
    "#table13 = table11.get_text()\n",
    "#print(table13) \n",
    "\n",
    "    table11 = soup.find_all('div', attrs = {'class':'gnt_pr'}) \n",
    "    #print(table11)\n",
    "    datalist=[]\n",
    "    linksdata=[]\n",
    "#print(table11)\n",
    "    for ik in table1:\n",
    "        datalist.append(ik.get_text())\n",
    "        print(ik.get_text())\n",
    "\n",
    "    pos=0\n",
    "    listtocheck=[]\n",
    "    for ik in table1:\n",
    "        links = re.findall(\"href=[\\\"\\'](.*?)[\\\"\\']\", str(ik))\n",
    "        linksdata.append('https://www.usatoday.com'+links[0])\n",
    "        if 'story' not in links[0]:\n",
    "            listtocheck.append(pos)\n",
    "        pos+=1\n",
    "        print(links)\n",
    "\n",
    "    print(\"list check is \",listtocheck)\n",
    "\n",
    "    for ij in range(len(listtocheck)):\n",
    "        print(ij)\n",
    "        datalist.pop(ij)\n",
    "        linksdata.pop(ij)\n",
    "    #print(listtocheck[ij])\n",
    "\n",
    "    print(len(datalist))\n",
    "    print(len(linksdata))\n",
    "    return datalist,linksdata\n",
    "\n",
    "\n",
    "#df\n",
    "df1=pd1.read_csv('fortune500.csv')\n",
    "df=pd.DataFrame()\n",
    "app = Flask(__name__)\n",
    "\n",
    "class ExampleForm(Form):\n",
    "    dt = DateField('container', format='%d-%m-%Y')\n",
    "\n",
    "@app.route(\"/parsenews\")\n",
    "def parsenews(): \n",
    "    newsinfo = request.args.get('msg')\n",
    "    URL =newsinfo.rstrip().lstrip().strip()# \"https://www.hindustantimes.com/delhi-news/protest-at-delhi-s-jama-masjid-against-citizenship-act-4-metro-stations-closed-in-area/story-q7vKj5IUdIKMExw5eGBfxI.html\"\n",
    "    #URL =\"https://www.hindustantimes.com/delhi-news/protest-at-delhi-s-jama-masjid-against-citizenship-act-4-metro-stations-closed-in-area/story-q7vKj5IUdIKMExw5eGBfxI.html\"\n",
    "    #print repr(URL)\n",
    "    r = requests.get(URL) \n",
    "    #print(r)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser') \n",
    "  \n",
    "    quotes=[]  # a list to store quotes \n",
    "  \n",
    "    table = soup.find('div', attrs = {'class':'gnt_ar_b'}) \n",
    "    #print(table)\n",
    "    alltestdata='<a href=\\''+URL+'\\' target=\"_blank\" >'+URL+'</a>'+'<br>'\n",
    "    print(alltestdata)\n",
    "    try:\n",
    "        table1 = table.find_all('p')\n",
    "        \n",
    "        for row in table.find_all('p'):\n",
    "            quote = {} \n",
    "            quote['data'] = row.text \n",
    "            alltestdata=alltestdata+row.text+\" \"\n",
    "            quotes.append(quote)\n",
    "    except:\n",
    "        alltestdata='<a href=\\''+URL+'\\' target=\"_blank\" >'+URL+'</a>'+'<br>'\n",
    "    #print(alltestdata)\n",
    "    print(alltestdata)\n",
    "    return alltestdata\n",
    "\n",
    "@app.route(\"/searchforcompany\")\n",
    "def searchforcompany():\n",
    "    global df\n",
    "    legend = 'Stock Price data'\n",
    "    company = request.args.get('company')\n",
    "    dfop=df1.loc[df1['Name'] == company]\n",
    "    op1=str(dfop['Symbol'].iloc[0])\n",
    "    print(op1)\n",
    "    df=pd1.read_csv('data//'+op1+'.csv')\n",
    "    temperatures = list(df['Close'])\n",
    "    times = list(df['Date'])\n",
    "    \n",
    "    datalist,linksdata=callingnews(company)\n",
    "    dictis={}\n",
    "    for ims in range(len(datalist)):\n",
    "        dictis[datalist[ims]]=linksdata[ims]\n",
    "        \n",
    "    print(dictis)\n",
    "    urlofsite='https://www.usatoday.com'\n",
    "    io=0\n",
    "    return render_template('line_chart.html',dictdata=dictis,links=linksdata,news=datalist, values=temperatures, labels=times, legend=legend,stockname=company,symbolis=op1)\n",
    "    #return op1\n",
    "\n",
    "@app.route(\"/futurepriceprediction\")\n",
    "def futurepriceprediction():\n",
    "    companySymbol = request.args.get('msg')\n",
    "    dictis=predictpriceofdata(companySymbol)\n",
    "    #print('price is')\n",
    "    print(dictis)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return dictis   \n",
    "    \n",
    "@app.route(\"/fetchprice\")\n",
    "def fetchprice():\n",
    "    company = request.args.get('msg')\n",
    "    priceis=getpriceinfo(company)#'1211'#fetchcurrentmarketprice(company)\n",
    "    print('price is')\n",
    "    print(priceis)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return str(priceis)\n",
    "\n",
    "\n",
    "@app.route(\"/getqoutetableval\")\n",
    "def getqoutetableval():\n",
    "    company = request.args.get('msg')\n",
    "    print('company for qoute '+company)\n",
    "    qoute=getqoutetable(company)#'1211'#fetchcurrentmarketprice(company)\n",
    "    print('qoute is')\n",
    "    print(qoute)\n",
    "    df_list = qoute.values.tolist()\n",
    "    alldata=''\n",
    "    for ik in range(len(df_list)):\n",
    "        alldata=alldata+str(df_list[ik][0])+\" :- \"+str(df_list[ik][1])+\"<br>\\n\"\n",
    "    #JSONP_data = jsonpify(df_list)\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return alldata\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    temperatures = dict(df1['Name'])\n",
    "    sendingcompaniesinfo={}\n",
    "    for keys in temperatures: \n",
    "        temperatures[keys] = str(temperatures[keys]) \n",
    "        sendingcompaniesinfo[temperatures[keys]]='null'\n",
    "    #print(sendingcompaniesinfo)\n",
    "    return render_template('searching.html', values=sendingcompaniesinfo)\n",
    "\n",
    "@app.route(\"/prediction\", methods=[\"GET\", \"POST\"])\n",
    "def prediction():\n",
    "    \n",
    "    return render_template('prediction.html')\n",
    "\n",
    "\n",
    "@app.route(\"/simple_chart\")\n",
    "def chart():\n",
    "    legend = 'Monthly Data'\n",
    "    labels = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\"]\n",
    "    values = [10, 9, 8, 7, 6, 4, 7, 8]\n",
    "    return render_template('chart.html', values=values, labels=labels, legend=legend)\n",
    "\n",
    "\n",
    "@app.route(\"/line_chart\")\n",
    "def line_chart():\n",
    "    legend = 'Temperatures'\n",
    "    temperatures = list(df['Close'])\n",
    "    times = list(df['Date'])\n",
    "    return render_template('line_chart.html', values=temperatures, labels=times, legend=legend)\n",
    "\n",
    "@app.route(\"/price\")\n",
    "def price():\n",
    "    global df\n",
    "    userText = request.args.get('msg')\n",
    "    print(userText)\n",
    "    op=dict(df.iloc[int(userText)])#tuple(list(df.iloc[int(userText)]))\n",
    "    print(op)\n",
    "    #for dicts in test_list: \n",
    "    for keys in op: \n",
    "        op[keys] = str(op[keys]) \n",
    "    return op\n",
    "\n",
    "\n",
    "@app.route(\"/time_chart\", methods=['POST','GET'])\n",
    "def time_chart():\n",
    "    '''legend = 'Temperatures'\n",
    "    temperatures = [73.7, 73.4, 73.8, 72.8, 68.7, 65.2,\n",
    "                    61.8, 58.7, 58.2, 58.3, 60.5, 65.7,\n",
    "                    70.2, 71.4, 71.2, 70.9, 71.3, 71.1]\n",
    "    times = [time(hour=11, minute=14, second=15),\n",
    "             time(hour=11, minute=14, second=30),\n",
    "             time(hour=11, minute=14, second=45),\n",
    "             time(hour=11, minute=15, second=00),\n",
    "             time(hour=11, minute=15, second=15),\n",
    "             time(hour=11, minute=15, second=30),\n",
    "             time(hour=11, minute=15, second=45),\n",
    "             time(hour=11, minute=16, second=00),\n",
    "             time(hour=11, minute=16, second=15),\n",
    "             time(hour=11, minute=16, second=30),\n",
    "             time(hour=11, minute=16, second=45),\n",
    "             time(hour=11, minute=17, second=00),\n",
    "             time(hour=11, minute=17, second=15),\n",
    "             time(hour=11, minute=17, second=30),\n",
    "             time(hour=11, minute=17, second=45),\n",
    "             time(hour=11, minute=18, second=00),\n",
    "             time(hour=11, minute=18, second=15),\n",
    "             time(hour=11, minute=18, second=30)]'''\n",
    "    \n",
    "    #return render_template('time_chart.html', values=temperatures, labels=times, legend=legend)\n",
    "    return render_template('time_chart.html')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run('0.0.0.0')\n",
    "    #app.run('0.0.0.0',port=80)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-67-f8b3b1e59c1a>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-67-f8b3b1e59c1a>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    X_predict = []\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# create future predict list which is a two dimensional list of values.\n",
    "        # the first dimension is the total number of future days\n",
    "        # the second dimension is the list of values of prediction_window_size size\n",
    "        X_predict = []\n",
    "        for i in range(prediction_window_size,inputs.shape[0]):\n",
    "            X_predict.append(inputs[i-prediction_window_size:i,0])\n",
    "        X_predict = np.array(X_predict)\n",
    "\n",
    "# predict the future\n",
    "        X_predict = np.reshape(X_predict, (X_predict.shape[0],X_predict.shape[1],1))\n",
    "        future_closing_price = model.predict(X_predict)\n",
    "\n",
    "        train, valid = train_test_split(new_data, train_size=0.99, test_size=0.01, shuffle=False)\n",
    "        date_index = pd.to_datetime(train.index)\n",
    "\n",
    "#converting dates into number of days as dates cannot be passed directly to any regression model\n",
    "        x_days = (date_index - pd.to_datetime('1970-01-01')).days\n",
    "\n",
    "# we are doing prediction for next 5 years hence prediction_for_days is set to 1500 days.\n",
    "        prediction_for_days = 60\n",
    "        future_closing_price = future_closing_price[:prediction_for_days]\n",
    "\n",
    "# create a data index for future dates\n",
    "        x_predict_future_dates = np.asarray(pd.RangeIndex(start=x_days[-1] + 1, stop=x_days[-1] + 1 + (len(future_closing_price))))\n",
    "        future_date_index = pd.to_datetime(x_predict_future_dates, origin='1970-01-01', unit='D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as ml\n",
    "print(ml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
