{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas_datareader\n",
    "# !pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18032/2323382879.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#Test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_historical_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TSLA'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18032/2323382879.py\u001b[0m in \u001b[0;36mget_historical_data\u001b[1;34m(name, number_of_days)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://finance.yahoo.com/quote/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/history/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murllib2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'table'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtbody\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0meach_row\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pro\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pro\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pro\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[1;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             response = self.parent.error(\n\u001b[0m\u001b[0;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pro\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pro\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pro\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import urllib.request as urllib2\n",
    "except ImportError:\n",
    "    import urllib2\n",
    "from bs4 import BeautifulSoup as bs\n",
    "#https://finance.yahoo.com/quote/amzn/history/\n",
    "def get_historical_data(name, number_of_days):\n",
    "    data = []\n",
    "    url = \"https://finance.yahoo.com/quote/\" + name + \"/history/\"\n",
    "    rows = bs(urllib2.urlopen(url).read()).findAll('table')[0].tbody.findAll('tr')\n",
    "\n",
    "    for each_row in rows:\n",
    "        divs = each_row.findAll('td')\n",
    "        #print(divs)\n",
    "        if divs[1].span.text  != 'Dividend': #Ignore this row in the table\n",
    "            #I'm only interested in 'Open' price; For other values, play with divs[1 - 5]\n",
    "            data.append({'Date': divs[0].span.text, 'Close': float(divs[4].span.text.replace(',',''))})\n",
    "    print(len(data))\n",
    "    return data[:number_of_days]\n",
    "\n",
    "#Test\n",
    "for i in get_historical_data('TSLA', 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "TSLA_2020–04–25\n"
     ]
    }
   ],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "from datetime import date\n",
    "import yfinance as yf\n",
    "yf.pdr_override()\n",
    "import pandas as pd\n",
    "# Tickers list\n",
    "# We can add and delete any ticker from the list to get desired ticker live data\n",
    "ticker_list=['TSLA']\n",
    "today = date.today()\n",
    "# We can get data by our choice by giving days bracket\n",
    "start_date= \"2020–04–21\"\n",
    "end_date=\"2020–04–25\"\n",
    "files=[]\n",
    "def getData(ticker):\n",
    "    print (ticker)\n",
    "    data = pdr.get_data_yahoo(ticker, start='2015-01-01', end='2020-06-12',)\n",
    "    dataname= ticker+'_'+str(end_date)\n",
    "    print(dataname)\n",
    "    files.append(dataname)\n",
    "    SaveData(data, dataname)\n",
    "# Create a data folder in your current dir.\n",
    "def SaveData(df, filename):\n",
    "    df.to_csv(filename+'.csv')\n",
    "#This loop will iterate over ticker list, will pass one ticker to get data, and save that data as file.\n",
    "for tik in ticker_list:\n",
    "    getData(tik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>137.089996</td>\n",
       "      <td>137.279999</td>\n",
       "      <td>134.520004</td>\n",
       "      <td>134.520004</td>\n",
       "      <td>134.520004</td>\n",
       "      <td>4523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>136.250000</td>\n",
       "      <td>136.610001</td>\n",
       "      <td>133.139999</td>\n",
       "      <td>133.899994</td>\n",
       "      <td>133.899994</td>\n",
       "      <td>7599900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>133.429993</td>\n",
       "      <td>135.479996</td>\n",
       "      <td>131.809998</td>\n",
       "      <td>134.690002</td>\n",
       "      <td>134.690002</td>\n",
       "      <td>8851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>134.600006</td>\n",
       "      <td>134.729996</td>\n",
       "      <td>131.649994</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>7178800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>132.009995</td>\n",
       "      <td>132.320007</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>11030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>2389.949951</td>\n",
       "      <td>2444.979980</td>\n",
       "      <td>2386.050049</td>\n",
       "      <td>2393.610107</td>\n",
       "      <td>2393.610107</td>\n",
       "      <td>5770700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>2416.610107</td>\n",
       "      <td>2428.310059</td>\n",
       "      <td>2279.659912</td>\n",
       "      <td>2328.120117</td>\n",
       "      <td>2328.120117</td>\n",
       "      <td>7476700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>2369.000000</td>\n",
       "      <td>2394.000000</td>\n",
       "      <td>2351.000000</td>\n",
       "      <td>2363.489990</td>\n",
       "      <td>2363.489990</td>\n",
       "      <td>4218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>2399.979980</td>\n",
       "      <td>2424.219971</td>\n",
       "      <td>2382.080078</td>\n",
       "      <td>2399.449951</td>\n",
       "      <td>2399.449951</td>\n",
       "      <td>5066600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2420.429932</td>\n",
       "      <td>2382.000000</td>\n",
       "      <td>2410.219971</td>\n",
       "      <td>2410.219971</td>\n",
       "      <td>3824900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2596 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Open         High          Low        Close  \\\n",
       "0     2009-12-31   137.089996   137.279999   134.520004   134.520004   \n",
       "1     2010-01-04   136.250000   136.610001   133.139999   133.899994   \n",
       "2     2010-01-05   133.429993   135.479996   131.809998   134.690002   \n",
       "3     2010-01-06   134.600006   134.729996   131.649994   132.250000   \n",
       "4     2010-01-07   132.009995   132.320007   128.800003   130.000000   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "2591  2020-04-20  2389.949951  2444.979980  2386.050049  2393.610107   \n",
       "2592  2020-04-21  2416.610107  2428.310059  2279.659912  2328.120117   \n",
       "2593  2020-04-22  2369.000000  2394.000000  2351.000000  2363.489990   \n",
       "2594  2020-04-23  2399.979980  2424.219971  2382.080078  2399.449951   \n",
       "2595  2020-04-24  2417.000000  2420.429932  2382.000000  2410.219971   \n",
       "\n",
       "        Adj Close    Volume  \n",
       "0      134.520004   4523000  \n",
       "1      133.899994   7599900  \n",
       "2      134.690002   8851900  \n",
       "3      132.250000   7178800  \n",
       "4      130.000000  11030200  \n",
       "...           ...       ...  \n",
       "2591  2393.610107   5770700  \n",
       "2592  2328.120117   7476700  \n",
       "2593  2363.489990   4218300  \n",
       "2594  2399.449951   5066600  \n",
       "2595  2410.219971   3824900  \n",
       "\n",
       "[2596 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd1\n",
    "df=pd1.read_csv('data//amzn.csv')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "op=dict(df.loc[10])\n",
    "for keys in op: \n",
    "    op[keys] = str(op[keys]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': '2010-01-15',\n",
       " 'Open': '129.17999267578122',\n",
       " 'High': '129.64999389648438',\n",
       " 'Low': '127.05999755859376',\n",
       " 'Close': '127.13999938964844',\n",
       " 'Adj Close': '127.13999938964844',\n",
       " 'Volume': '15376500'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Getting just the adjusted closing prices. This will return a Pandas DataFrame\n",
    "# The index in this DataFrame is the major index of the panel_data.\n",
    "close = panel_data['Close']\n",
    "\n",
    "# Getting all weekdays between 01/01/2000 and 12/31/2016\n",
    "all_weekdays = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "\n",
    "# How do we align the existing prices in adj_close with our new set of dates?\n",
    "# All we need to do is reindex close using all_weekdays as the new index\n",
    "close = close.reindex(all_weekdays)\n",
    "\n",
    "# Reindexing will insert missing values (NaN) for the dates that were not present\n",
    "# in the original set. To cope with this, we can fill the missing by replacing them\n",
    "# with the latest available price for each instrument.\n",
    "close = close.fillna(method='ffill')\n",
    "print(all_weekdays)\n",
    "\n",
    "close.head(10)\n",
    "\n",
    "close.describe()\n",
    "\n",
    "# Get the MSFT timeseries. This now returns a Pandas Series object indexed by date.\n",
    "msft = close.loc[:, 'MSFT']\n",
    "\n",
    "# Calculate the 20 and 100 days moving averages of the closing prices\n",
    "short_rolling_msft = msft.rolling(window=20).mean()\n",
    "long_rolling_msft = msft.rolling(window=100).mean()\n",
    "\n",
    "# Plot everything by leveraging the very powerful matplotlib package\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "ax.plot(msft.index, msft, label='MSFT')\n",
    "ax.plot(short_rolling_msft.index, short_rolling_msft, label='20 days rolling')\n",
    "ax.plot(long_rolling_msft.index, long_rolling_msft, label='100 days rolling')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Adjusted closing price ($)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MMM', 'AOS', 'ABT', 'ABBV', 'ACN', 'ATVI', 'AYI', 'ADBE', 'AAP', 'AMD', 'AES', 'AET', 'AMG', 'AFL', 'A', 'APD', 'AKAM', 'ALK', 'ALB', 'ARE', 'ALXN', 'ALGN', 'ALLE', 'AGN', 'ADS', 'LNT', 'ALL', 'GOOGL', 'GOOG', 'MO', 'AMZN', 'AEE', 'AAL', 'AEP', 'AXP', 'AIG', 'AMT', 'AWK', 'AMP', 'ABC', 'AME', 'AMGN', 'APH', 'APC', 'ADI', 'ANDV', 'ANSS', 'ANTM', 'AON', 'APA', 'AIV', 'AAPL', 'AMAT', 'APTV', 'ADM', 'ARNC', 'AJG', 'AIZ', 'T', 'ADSK', 'ADP', 'AZO', 'AVB', 'AVY', 'BHGE', 'BLL', 'BAC', 'BAX', 'BBT', 'BDX', 'BRK.B', 'BBY', 'BIIB', 'BLK', 'HRB', 'BA', 'BKNG', 'BWA', 'BXP', 'BSX', 'BHF', 'BMY', 'AVGO', 'BF.B', 'CHRW', 'CA', 'COG', 'CDNS', 'CPB', 'COF', 'CAH', 'KMX', 'CCL', 'CAT', 'CBOE', 'CBRE', 'CBS', 'CELG', 'CNC', 'CNP', 'CTL', 'CERN', 'CF', 'SCHW', 'CHTR', 'CVX', 'CMG', 'CB', 'CHD', 'CI', 'XEC', 'CINF', 'CTAS', 'CSCO', 'C', 'CFG', 'CTXS', 'CME', 'CMS', 'KO', 'CTSH', 'CL', 'CMCSA', 'CMA', 'CAG', 'CXO', 'COP', 'ED', 'STZ', 'GLW', 'COST', 'COTY', 'CCI', 'CSRA', 'CSX', 'CMI', 'CVS', 'DHI', 'DHR', 'DRI', 'DVA', 'DE', 'DAL', 'XRAY', 'DVN', 'DLR', 'DFS', 'DISCA', 'DISCK', 'DISH', 'DG', 'DLTR', 'D', 'DOV', 'DWDP', 'DPS', 'DTE', 'DUK', 'DRE', 'DXC', 'ETFC', 'EMN', 'ETN', 'EBAY', 'ECL', 'EIX', 'EW', 'EA', 'EMR', 'ETR', 'EVHC', 'EOG', 'EQT', 'EFX', 'EQIX', 'EQR', 'ESS', 'EL', 'RE', 'ES', 'EXC', 'EXPE', 'EXPD', 'ESRX', 'EXR', 'XOM', 'FFIV', 'FB', 'FAST', 'FRT', 'FDX', 'FIS', 'FITB', 'FE', 'FISV', 'FLIR', 'FLS', 'FLR', 'FMC', 'FL', 'F', 'FTV', 'FBHS', 'BEN', 'FCX', 'GPS', 'GRMN', 'IT', 'GD', 'GE', 'GGP', 'GIS', 'GM', 'GPC', 'GILD', 'GPN', 'GS', 'GT', 'GWW', 'HAL', 'HBI', 'HOG', 'HRS', 'HIG', 'HAS', 'HCA', 'HCP', 'HP', 'HSIC', 'HES', 'HPE', 'HLT', 'HOLX', 'HD', 'HON', 'HRL', 'HST', 'HPQ', 'HUM', 'HBAN', 'HII', 'IDXX', 'INFO', 'ITW', 'ILMN', 'INCY', 'IR', 'INTC', 'ICE', 'IBM', 'IP', 'IPG', 'IFF', 'INTU', 'ISRG', 'IVZ', 'IPGP', 'IQV', 'IRM', 'JBHT', 'JEC', 'SJM', 'JNJ', 'JCI', 'JPM', 'JNPR', 'KSU', 'K', 'KEY', 'KMB', 'KIM', 'KMI', 'KLAC', 'KSS', 'KHC', 'KR', 'LB', 'LLL', 'LH', 'LRCX', 'LEG', 'LEN', 'LUK', 'LLY', 'LNC', 'LKQ', 'LMT', 'L', 'LOW', 'LYB', 'MTB', 'MAC', 'M', 'MRO', 'MPC', 'MAR', 'MMC', 'MLM', 'MAS', 'MA', 'MAT', 'MKC', 'MCD', 'MCK', 'MDT', 'MRK', 'MET', 'MTD', 'MGM', 'KORS', 'MCHP', 'MU', 'MSFT', 'MAA', 'MHK', 'TAP', 'MDLZ', 'MON', 'MNST', 'MCO', 'MS', 'MSI', 'MYL', 'NDAQ', 'NOV', 'NAVI', 'NKTR', 'NTAP', 'NFLX', 'NWL', 'NFX', 'NEM', 'NWSA', 'NWS', 'NEE', 'NLSN', 'NKE', 'NI', 'NBL', 'JWN', 'NSC', 'NTRS', 'NOC', 'NCLH', 'NRG', 'NUE', 'NVDA', 'ORLY', 'OXY', 'OMC', 'OKE', 'ORCL', 'PCAR', 'PKG', 'PH', 'PAYX', 'PYPL', 'PNR', 'PBCT', 'PEP', 'PKI', 'PRGO', 'PFE', 'PCG', 'PM', 'PSX', 'PNW', 'PXD', 'PNC', 'RL', 'PPG', 'PPL', 'PX', 'PFG', 'PG', 'PGR', 'PLD', 'PRU', 'PEG', 'PSA', 'PHM', 'PVH', 'QRVO', 'QCOM', 'PWR', 'DGX', 'RRC', 'RJF', 'RTN', 'O', 'RHT', 'REG', 'REGN', 'RF', 'RSG', 'RMD', 'RHI', 'ROK', 'COL', 'ROP', 'ROST', 'RCL', 'SPGI', 'CRM', 'SBAC', 'SCG', 'SLB', 'STX', 'SEE', 'SRE', 'SHW', 'SPG', 'SWKS', 'SLG', 'SNA', 'SO', 'LUV', 'SWK', 'SBUX', 'STT', 'SRCL', 'SYK', 'STI', 'SIVB', 'SYMC', 'SYF', 'SNPS', 'SYY', 'TROW', 'TTWO', 'TPR', 'TGT', 'TEL', 'FTI', 'TXN', 'TXT', 'BK', 'CLX', 'COO', 'HSY', 'MOS', 'TRV', 'DIS', 'TMO', 'TIF', 'TWX', 'TJX', 'TMK', 'TSS', 'TSCO', 'TDG', 'TRIP', 'FOXA', 'FOX', 'TSN', 'USB', 'UDR', 'ULTA', 'UAA', 'UA', 'UNP', 'UAL', 'UNH', 'UPS', 'URI', 'UTX', 'UHS', 'UNM', 'VFC', 'VLO', 'VAR', 'VTR', 'VRSN', 'VRSK', 'VZ', 'VRTX', 'VIAB', 'V', 'VNO', 'VMC', 'WMT', 'WBA', 'WM', 'WAT', 'WEC', 'WFC', 'WELL', 'WDC', 'WU', 'WRK', 'WY', 'WHR', 'WMB', 'WLTW', 'WYN', 'WYNN', 'XEL', 'XRX', 'XLNX', 'XL', 'XYL', 'YUM', 'ZBH', 'ZION', 'ZTS']\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "data_source='2010-01-01' is not implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8a179b834ea8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mpanel_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data//'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mik\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mfetchpriceandsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-8a179b834ea8>\u001b[0m in \u001b[0;36mfetchpriceandsave\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# User pandas_reader.data.DataReader to load the desired data. As simple as that.\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mik\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtickers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mpanel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mik\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#print(panel_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\project\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\project\\lib\\site-packages\\pandas_datareader\\data.py\u001b[0m in \u001b[0;36mDataReader\u001b[1;34m(name, data_source, start, end, retry_count, pause, session, api_key)\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_source\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexpected_source\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data_source=%r is not implemented\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdata_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_source\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"yahoo\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: data_source='2010-01-01' is not implemented"
     ]
    }
   ],
   "source": [
    "#final fetching price from all\n",
    "\n",
    "\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# We would like all available data from 01/01/2000 until 12/31/2016.\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2020-04-25'\n",
    "df1=pd.read_csv('fortune500.csv')\n",
    "tickers = list(df1['Symbol'])\n",
    "print(tickers)\n",
    "def fetchpriceandsave():\n",
    "    \n",
    "# User pandas_reader.data.DataReader to load the desired data. As simple as that.\\\n",
    "    for ik in tickers:\n",
    "        panel_data = data.DataReader(ik,'yahoo', start_date, end_date)\n",
    "\n",
    "        #print(panel_data)\n",
    "\n",
    "        panel_data.to_csv('data//'+ik+'.csv')\n",
    "\n",
    "fetchpriceandsave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://in.finance.yahoo.com/quote/amzn\n",
      "2410.22\n",
      "2,417.00\n",
      " data-test=\"FIFTY_TWO_WK_RANGE-value\">1,626.03 - 2,461.00</td></tr><tr class=\"Bxz(bb) Bdbw(1px) Bdbs(s) Bdc($seperatorColor) H(36px)\" data-reactid=\"68\"><td class=\"C($primaryColor) W(51%)\" data-reactid=\"69\"><span data-reactid=\"70\">Volume\n",
      "completed...\n"
     ]
    }
   ],
   "source": [
    "### Extract from Yahoo Link ###\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests_html\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "#import unidecode\n",
    "ticker_list1=[\"amzn\"]\n",
    "for ticker in ticker_list1:\n",
    "    url = 'https://in.finance.yahoo.com/quote/' + ticker\n",
    "    print(url)\n",
    "    session = requests_html.HTMLSession()\n",
    "    r = session.get(url)\n",
    "    content = BeautifulSoup(r.content, 'html')\n",
    "    try:\n",
    "        price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #print(str(content).split('data-reactid=\"47\"'))\n",
    "        openprice = str(content).split('data-reactid=\"49\"')[3].split('</span>')[0].replace('>','')\n",
    "        rangeobt = str(content).split('data-reactid=\"67\"')[2].split('</span>')[0]\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "    except IndexError as e:\n",
    "        price = 0.00\n",
    "    price = price or \"0\"\n",
    "    try:\n",
    "        price = float(price.replace(',',''))\n",
    "    except ValueError as e:\n",
    "        price = 0.00\n",
    "    time.sleep(1)\n",
    "   \n",
    "    print( price)\n",
    "    print(openprice)\n",
    "    print(rangeobt)\n",
    "        #cursor.execute(_SQL, (unidecode.unidecode(ticker[0]), price, unidecode.unidecode(ticker[1]), unidecode.unidecode(ticker[2]), unidecode.unidecode(ticker[3])))\n",
    "print('completed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests_html\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "def fetchcurrentmarketprice(stock):\n",
    "    stock1=stock\n",
    "    #for ticker in ticker_list1:\n",
    "    url = 'https://in.finance.yahoo.com/quote/' + stock1\n",
    "    print(url)\n",
    "    session = requests_html.HTMLSession()\n",
    "    r = session.get(url)\n",
    "    content = BeautifulSoup(r.content, 'html')\n",
    "    try:\n",
    "        price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #print(str(content).split('data-reactid=\"47\"'))\n",
    "        openprice = str(content).split('data-reactid=\"49\"')[3].split('</span>')[0].replace('>','')\n",
    "        rangeobt = str(content).split('data-reactid=\"67\"')[2].split('</span>')[0]\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "        #price = str(content).split('data-reactid=\"32\"')[4].split('</span>')[0].replace('>','')\n",
    "    except IndexError as e:\n",
    "        price = 0.00\n",
    "        price = price or \"0\"\n",
    "    try:\n",
    "        price = float(price.replace(',',''))\n",
    "    except ValueError as e:\n",
    "        price = 0.00\n",
    "        time.sleep(1)\n",
    "   \n",
    "    print( price)\n",
    "    print(openprice)\n",
    "    print(rangeobt)\n",
    "        #cursor.execute(_SQL, (unidecode.unidecode(ticker[0]), price, unidecode.unidecode(ticker[1]), unidecode.unidecode(ticker[2]), unidecode.unidecode(ticker[3])))\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://in.finance.yahoo.com/quote/amzn\n",
      "2410.22\n",
      "2,417.00\n",
      " data-test=\"FIFTY_TWO_WK_RANGE-value\">1,626.03 - 2,461.00</td></tr><tr class=\"Bxz(bb) Bdbw(1px) Bdbs(s) Bdc($seperatorColor) H(36px)\" data-reactid=\"68\"><td class=\"C($primaryColor) W(51%)\" data-reactid=\"69\"><span data-reactid=\"70\">Volume\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2410.22"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetchcurrentmarketprice('amzn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for aapl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\.conda\\envs\\project\\lib\\site-packages\\urllib3\\connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'finance.yahoo.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing http://finance.yahoo.com/quote/aapl?p=aapl\n",
      "OrderedDict([('', '303.75'), ('1y Target Est', 303.75), ('EPS (TTM)', 12.595), ('Earnings Date', '2020-04-30'), ('ticker', 'aapl'), ('url', 'http://finance.yahoo.com/quote/aapl?p=aapl')])\n",
      "Writing data to output file\n"
     ]
    }
   ],
   "source": [
    "from lxml import html  \n",
    "import requests\n",
    "from time import sleep\n",
    "import json\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "from time import sleep\n",
    "\n",
    "def parse(ticker):\n",
    "\turl = \"http://finance.yahoo.com/quote/%s?p=%s\"%(ticker,ticker)\n",
    "    #print(url)\n",
    "\tresponse = requests.get(url, verify=False)\n",
    "\tprint (\"Parsing %s\"%(url))\n",
    "\tsleep(4)\n",
    "\tparser = html.fromstring(response.text)\n",
    "\tsummary_table = parser.xpath('//div[contains(@data-test,\"summary-table\")]//tr')\n",
    "\tsummary_data = OrderedDict()\n",
    "\tother_details_json_link = \"https://query2.finance.yahoo.com/v10/finance/quoteSummary/{0}?formatted=true&lang=en-US&region=US&modules=summaryProfile%2CfinancialData%2CrecommendationTrend%2CupgradeDowngradeHistory%2Cearnings%2CdefaultKeyStatistics%2CcalendarEvents&corsDomain=finance.yahoo.com\".format(ticker)\n",
    "\tsummary_json_response = requests.get(other_details_json_link)\n",
    "\ttry:\n",
    "\t\tjson_loaded_summary =  json.loads(summary_json_response.text)\n",
    "\t\ty_Target_Est = json_loaded_summary[\"quoteSummary\"][\"result\"][0][\"financialData\"][\"targetMeanPrice\"]['raw']\n",
    "\t\tearnings_list = json_loaded_summary[\"quoteSummary\"][\"result\"][0][\"calendarEvents\"]['earnings']\n",
    "\t\teps = json_loaded_summary[\"quoteSummary\"][\"result\"][0][\"defaultKeyStatistics\"][\"trailingEps\"]['raw']\n",
    "\t\tdatelist = []\n",
    "\t\tfor i in earnings_list['earningsDate']:\n",
    "\t\t\tdatelist.append(i['fmt'])\n",
    "\t\tearnings_date = ' to '.join(datelist)\n",
    "\t\tfor table_data in summary_table:\n",
    "\t\t\traw_table_key = table_data.xpath('.//td[contains(@class,\"C(black)\")]//text()')\n",
    "\t\t\traw_table_value = table_data.xpath('.//td[contains(@class,\"Ta(end)\")]//text()')\n",
    "\t\t\ttable_key = ''.join(raw_table_key).strip()\n",
    "\t\t\ttable_value = ''.join(raw_table_value).strip()\n",
    "\t\t\tsummary_data.update({table_key:table_value})\n",
    "\t\tsummary_data.update({'1y Target Est':y_Target_Est,'EPS (TTM)':eps,'Earnings Date':earnings_date,'ticker':ticker,'url':url})\n",
    "\t\treturn summary_data\n",
    "\texcept:\n",
    "\t\tprint (\"Failed to parse json response\")\n",
    "\t\treturn {\"error\":\"Failed to parse json response\"}\n",
    "\t\t\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "\tticker = \"aapl\"\n",
    "\tprint (\"Fetching data for %s\"%(ticker))\n",
    "\tscraped_data = parse(ticker)\n",
    "\tprint(scraped_data)\n",
    "\tprint (\"Writing data to output file\")\n",
    "\twith open('%s-summary.json'%(ticker),'w') as fp:\n",
    "\t\tjson.dump(scraped_data,fp,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "def fetchpriceandsave(val):\n",
    "    start_date = '2020-04-25'\n",
    "    end_date = '2020-04-26'    \n",
    "# User pandas_reader.data.DataReader to load the desired data. As simple as that.\\\n",
    "    #for ik in tickers:\n",
    "    panel_data = data.DataReader(val, start_date, end_date)\n",
    "\n",
    "        #print(panel_data)\n",
    "\n",
    "    panel_data.to_csv(val+'.csv')\n",
    "\n",
    "fetchpriceandsave('amzn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
